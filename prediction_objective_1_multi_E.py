# -*- coding: utf-8 -*-
"""1_multi_E_v3

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yviyDRGC2vSxMMbQ404F0-ZEwSjiUeDG

# **PROJECT: PREDICTION OF AIR TICKET PRICES FOR DOMESTIC FLIGHTS IN PERU ON LATAM AIRLINE**

------

# **ENTRENAMIENTO 1: OBJETIVO PREDECIR TARIFA**
"""

from IPython.display import display

# Importar las librer铆as necesarias
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Cargar el dataset
df = pd.read_csv('flights_data_final.csv')

# Mostrar las primeras filas
print("Primeras 5 filas del dataset:")
display(df.head())

"""## **MODELO 1: LSTM - Long Short-Term Memory**"""

import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Embedding, LSTM, Dense, Input, Concatenate, Reshape
from tensorflow.keras.optimizers import Adam
from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import TimeSeriesSplit
import optuna
import time

# Normalizaci贸n y preparaci贸n de datos
X = df[['Origen_int', 'Destino_int', 'Duracion_minutos', 'Directo_binario',
        'Dias_hasta_vuelo', 'Rango_Horario_Consulta_int', 'Hora_Salida_Rango_int', 'Hora_Llegada_Rango_int']]
y = df['Tarifa']

scaler = StandardScaler()
X.loc[:, ['Duracion_minutos', 'Dias_hasta_vuelo']] = scaler.fit_transform(X[['Duracion_minutos', 'Dias_hasta_vuelo']])


def objective(trial):
    #  Hiperpar谩metros a optimizar
    embedding_dim = trial.suggest_categorical('embedding_dim', [4, 8, 16])
    lstm_units = trial.suggest_categorical('lstm_units', [16, 32, 64])
    dense_units = trial.suggest_categorical('dense_units', [16, 32])
    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)
    learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-2, log=True)

    #  Divisi贸n en entrenamiento/validaci贸n
    split_index = int(len(X) * 0.8)
    X_train, X_val = X.iloc[:split_index], X.iloc[split_index:]
    y_train, y_val = y.iloc[:split_index], y.iloc[split_index:]

    #  Definici贸n del modelo
    input_origen = Input(shape=(1,))
    input_destino = Input(shape=(1,))
    input_rango_horario = Input(shape=(1,))
    input_salida = Input(shape=(1,))
    input_llegada = Input(shape=(1,))
    features = Input(shape=(3,))

    embedding_origen = Embedding(X['Origen_int'].nunique(), embedding_dim)(input_origen)
    embedding_destino = Embedding(X['Destino_int'].nunique(), embedding_dim)(input_destino)
    embedding_rango_horario = Embedding(X['Rango_Horario_Consulta_int'].nunique(), embedding_dim)(input_rango_horario)
    embedding_salida = Embedding(X['Hora_Salida_Rango_int'].nunique(), embedding_dim)(input_salida)
    embedding_llegada = Embedding(X['Hora_Llegada_Rango_int'].nunique(), embedding_dim)(input_llegada)

    features_reshaped = Reshape((1, 3))(features)
    x = Concatenate()([embedding_origen, embedding_destino, embedding_rango_horario,
                       embedding_salida, embedding_llegada, features_reshaped])
    x = LSTM(lstm_units, return_sequences=False)(x)
    x = Dense(dense_units, activation='relu')(x)
    output = Dense(1)(x)

    model = Model(inputs=[input_origen, input_destino, input_rango_horario,
                          input_salida, input_llegada, features], outputs=output)
    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mse')

    #  Entrenamiento (1 epoch para prueba)
    model.fit([X_train['Origen_int'], X_train['Destino_int'], X_train['Rango_Horario_Consulta_int'],
               X_train['Hora_Salida_Rango_int'], X_train['Hora_Llegada_Rango_int'],
               X_train[['Duracion_minutos', 'Directo_binario', 'Dias_hasta_vuelo']].values],
              y_train, epochs=100, batch_size=32, verbose=0)

    #  Evaluaci贸n
    y_pred = model.predict([X_val['Origen_int'], X_val['Destino_int'], X_val['Rango_Horario_Consulta_int'],
                            X_val['Hora_Salida_Rango_int'], X_val['Hora_Llegada_Rango_int'],
                            X_val[['Duracion_minutos', 'Directo_binario', 'Dias_hasta_vuelo']].values])

    return mean_absolute_error(y_val, y_pred)

#  Ejecutar Optuna (1 trial para prueba)
study = optuna.create_study(direction='minimize')
study.optimize(objective, n_trials=10)

#  Entrenamiento final con mejores par谩metros
best_params = study.best_params
embedding_dim = best_params['embedding_dim']
lstm_units = best_params['lstm_units']
dense_units = best_params['dense_units']
dropout_rate = best_params['dropout_rate']
learning_rate = best_params['learning_rate']

#  Divisi贸n simple
split_index = int(len(X) * 0.8)
X_train, X_val = X.iloc[:split_index], X.iloc[split_index:]
y_train, y_val = y.iloc[:split_index], y.iloc[split_index:]

#  Modelo final
input_origen = Input(shape=(1,))
input_destino = Input(shape=(1,))
input_rango_horario = Input(shape=(1,))
input_salida = Input(shape=(1,))
input_llegada = Input(shape=(1,))
features = Input(shape=(3,))

embedding_origen = Embedding(X['Origen_int'].nunique(), embedding_dim)(input_origen)
embedding_destino = Embedding(X['Destino_int'].nunique(), embedding_dim)(input_destino)
embedding_rango_horario = Embedding(X['Rango_Horario_Consulta_int'].nunique(), embedding_dim)(input_rango_horario)
embedding_salida = Embedding(X['Hora_Salida_Rango_int'].nunique(), embedding_dim)(input_salida)
embedding_llegada = Embedding(X['Hora_Llegada_Rango_int'].nunique(), embedding_dim)(input_llegada)

features_reshaped = Reshape((1, 3))(features)
x = Concatenate()([embedding_origen, embedding_destino, embedding_rango_horario,
                   embedding_salida, embedding_llegada, features_reshaped])
x = LSTM(lstm_units, return_sequences=False)(x)
x = Dense(dense_units, activation='relu')(x)
output = Dense(1)(x)

model = Model(inputs=[input_origen, input_destino, input_rango_horario,
                      input_salida, input_llegada, features], outputs=output)
model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mse')
start_time = time.time()
#  Entrenamiento final (1 epoch para prueba)
model.fit([X_train['Origen_int'], X_train['Destino_int'], X_train['Rango_Horario_Consulta_int'],
           X_train['Hora_Salida_Rango_int'], X_train['Hora_Llegada_Rango_int'],
           X_train[['Duracion_minutos', 'Directo_binario', 'Dias_hasta_vuelo']].values],
          y_train, epochs=100, batch_size=32, verbose=0)
end_time = time.time()  #  Fin del cron贸metro
training_time = end_time - start_time  #  Duraci贸n total en segundos
#  Predicci贸n final
y_pred = model.predict([X_val['Origen_int'], X_val['Destino_int'], X_val['Rango_Horario_Consulta_int'],
                        X_val['Hora_Salida_Rango_int'], X_val['Hora_Llegada_Rango_int'],
                        X_val[['Duracion_minutos', 'Directo_binario', 'Dias_hasta_vuelo']].values])

#  M茅tricas
mae = mean_absolute_error(y_val, y_pred)
mse = mean_squared_error(y_val, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_val, y_pred)

#  Resultados
final_metrics_lstm_obj1E = pd.Series({
    'MAE': mae,
    'MSE': mse,
    'RMSE': rmse,
    'R2': r2,
    'Training_Time': training_time,
    'Best_Params': str(best_params)
})

print(" M茅tricas finales (1 epoch):")
print(final_metrics_lstm_obj1E)

"""## **MODELO 2: GRU - Gated Recurrent Unit**"""

import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Embedding, GRU, Dense, Input, Concatenate, Reshape
from tensorflow.keras.optimizers import Adam
from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error
from sklearn.preprocessing import StandardScaler
import optuna
import time

# Normalizaci贸n de columnas num茅ricas
X = df[['Origen_int', 'Destino_int', 'Duracion_minutos', 'Directo_binario',
        'Dias_hasta_vuelo', 'Rango_Horario_Consulta_int', 'Hora_Salida_Rango_int', 'Hora_Llegada_Rango_int']]
y = df['Tarifa']

scaler = StandardScaler()
X.loc[:, ['Duracion_minutos', 'Dias_hasta_vuelo']] = scaler.fit_transform(X[['Duracion_minutos', 'Dias_hasta_vuelo']])

# Divisi贸n simple en entrenamiento y validaci贸n
train_size = int(0.8 * len(X))
X_train, X_val = X.iloc[:train_size], X.iloc[train_size:]
y_train, y_val = y.iloc[:train_size], y.iloc[train_size:]

# Funci贸n objetivo para Optuna
def objective_gru(trial):
    embedding_dim = trial.suggest_int('embedding_dim', 4, 16)
    gru_units = trial.suggest_int('gru_units', 32, 128)
    dense_units = trial.suggest_int('dense_units', 16, 128)
    learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-2, log=True)

    input_origen = Input(shape=(1,))
    input_destino = Input(shape=(1,))
    input_rango_horario = Input(shape=(1,))
    input_salida = Input(shape=(1,))
    input_llegada = Input(shape=(1,))
    features = Input(shape=(3,))

    embedding_origen = Embedding(input_dim=X['Origen_int'].nunique(), output_dim=embedding_dim)(input_origen)
    embedding_destino = Embedding(input_dim=X['Destino_int'].nunique(), output_dim=embedding_dim)(input_destino)
    embedding_rango_horario = Embedding(input_dim=X['Rango_Horario_Consulta_int'].nunique(), output_dim=embedding_dim)(input_rango_horario)
    embedding_salida = Embedding(input_dim=X['Hora_Salida_Rango_int'].nunique(), output_dim=embedding_dim)(input_salida)
    embedding_llegada = Embedding(input_dim=X['Hora_Llegada_Rango_int'].nunique(), output_dim=embedding_dim)(input_llegada)

    features_reshaped = Reshape((1, 3))(features)
    x = Concatenate()([embedding_origen, embedding_destino, embedding_rango_horario,
                       embedding_salida, embedding_llegada, features_reshaped])

    x = GRU(gru_units, return_sequences=False)(x)
    x = Dense(dense_units, activation='relu')(x)
    x = Dense(1)(x)

    model_gru = Model(inputs=[input_origen, input_destino, input_rango_horario,
                              input_salida, input_llegada, features], outputs=x)
    model_gru.compile(optimizer=Adam(learning_rate=learning_rate), loss='mse')

    model_gru.fit([X_train['Origen_int'], X_train['Destino_int'], X_train['Rango_Horario_Consulta_int'],
                   X_train['Hora_Salida_Rango_int'], X_train['Hora_Llegada_Rango_int'],
                   X_train[['Duracion_minutos', 'Directo_binario', 'Dias_hasta_vuelo']].values],
                  y_train, epochs=100, batch_size=32, verbose=0)

    y_pred = model_gru.predict([X_val['Origen_int'], X_val['Destino_int'], X_val['Rango_Horario_Consulta_int'],
                                X_val['Hora_Salida_Rango_int'], X_val['Hora_Llegada_Rango_int'],
                                X_val[['Duracion_minutos', 'Directo_binario', 'Dias_hasta_vuelo']].values])

    return np.sqrt(mean_squared_error(y_val, y_pred))

# Optuna para GRU con un solo trial
study_gru = optuna.create_study(direction='minimize')
study_gru.optimize(objective_gru, n_trials=10)

print("Best parameters (GRU):", study_gru.best_params)

# Evaluaci贸n final con los mejores par谩metros
best_params = study_gru.best_params
embedding_dim = best_params['embedding_dim']
gru_units = best_params['gru_units']
dense_units = best_params['dense_units']
learning_rate = best_params['learning_rate']

start_time = time.time()

input_origen = Input(shape=(1,))
input_destino = Input(shape=(1,))
input_rango_horario = Input(shape=(1,))
input_salida = Input(shape=(1,))
input_llegada = Input(shape=(1,))
features = Input(shape=(3,))

embedding_origen = Embedding(input_dim=X['Origen_int'].nunique(), output_dim=embedding_dim)(input_origen)
embedding_destino = Embedding(input_dim=X['Destino_int'].nunique(), output_dim=embedding_dim)(input_destino)
embedding_rango_horario = Embedding(input_dim=X['Rango_Horario_Consulta_int'].nunique(), output_dim=embedding_dim)(input_rango_horario)
embedding_salida = Embedding(input_dim=X['Hora_Salida_Rango_int'].nunique(), output_dim=embedding_dim)(input_salida)
embedding_llegada = Embedding(input_dim=X['Hora_Llegada_Rango_int'].nunique(), output_dim=embedding_dim)(input_llegada)

features_reshaped = Reshape((1, 3))(features)
x = Concatenate()([embedding_origen, embedding_destino, embedding_rango_horario,
                   embedding_salida, embedding_llegada, features_reshaped])

x = GRU(gru_units, return_sequences=False)(x)
x = Dense(dense_units, activation='relu')(x)
x = Dense(1)(x)

model_gru = Model(inputs=[input_origen, input_destino, input_rango_horario,
                          input_salida, input_llegada, features], outputs=x)
model_gru.compile(optimizer=Adam(learning_rate=learning_rate), loss='mse')

model_gru.fit([X_train['Origen_int'], X_train['Destino_int'], X_train['Rango_Horario_Consulta_int'],
               X_train['Hora_Salida_Rango_int'], X_train['Hora_Llegada_Rango_int'],
               X_train[['Duracion_minutos', 'Directo_binario', 'Dias_hasta_vuelo']].values],
              y_train, epochs=100, batch_size=32, verbose=0)

y_pred = model_gru.predict([X_val['Origen_int'], X_val['Destino_int'], X_val['Rango_Horario_Consulta_int'],
                            X_val['Hora_Salida_Rango_int'], X_val['Hora_Llegada_Rango_int'],
                            X_val[['Duracion_minutos', 'Directo_binario', 'Dias_hasta_vuelo']].values])

# M茅tricas finales
final_metrics = {
    'MAE': mean_absolute_error(y_val, y_pred),
    'MSE': mean_squared_error(y_val, y_pred),
    'RMSE': np.sqrt(mean_squared_error(y_val, y_pred)),
    'R2': r2_score(y_val, y_pred),
    'Training_Time': time.time() - start_time,
    'Best_Params': str(study_gru.best_params)
}

final_gru_metrics_obj1E = pd.Series(final_metrics)
print("Metricas finales GRU:")
print(final_gru_metrics_obj1E)

"""## **MODELO 3: TCN - Temporal Convolutional Networks**

Utilizan convoluciones causales para asegurar que la predicci贸n en un tiempo
t solo dependa de la informaci贸n de tiempos anteriores.
"""

import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Embedding, Dense, Input, Concatenate, Reshape
from tensorflow.keras.optimizers import Adam
from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error
from sklearn.preprocessing import StandardScaler
from tcn import TCN # Import TCN after successful installation
import optuna
import time

# Preparaci贸n de datos
X = df[['Origen_int', 'Destino_int', 'Duracion_minutos', 'Directo_binario',
        'Dias_hasta_vuelo', 'Rango_Horario_Consulta_int', 'Hora_Salida_Rango_int', 'Hora_Llegada_Rango_int']]
y = df['Tarifa']

scaler = StandardScaler()
X.loc[:, ['Duracion_minutos', 'Dias_hasta_vuelo']] = scaler.fit_transform(X[['Duracion_minutos', 'Dias_hasta_vuelo']])

# Definici贸n del objetivo de Optuna sin TimeSeriesSplit

def objective_tcn(trial):
    embedding_dim = trial.suggest_int('embedding_dim', 4, 16)
    tcn_filters = trial.suggest_int('tcn_filters', 32, 128)
    dense_units = trial.suggest_int('dense_units', 16, 128)
    learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-2, log=True)

    # Divisi贸n simple de datos
    train_size = int(0.8 * len(X))
    X_train, X_val = X.iloc[:train_size], X.iloc[train_size:]
    y_train, y_val = y.iloc[:train_size], y.iloc[train_size:]

    input_origen = Input(shape=(1,))
    input_destino = Input(shape=(1,))
    input_rango_horario = Input(shape=(1,))
    input_salida = Input(shape=(1,))
    input_llegada = Input(shape=(1,))
    features = Input(shape=(3,))

    embedding_origen = Embedding(input_dim=X['Origen_int'].nunique(), output_dim=embedding_dim)(input_origen)
    embedding_destino = Embedding(input_dim=X['Destino_int'].nunique(), output_dim=embedding_dim)(input_destino)
    embedding_rango_horario = Embedding(input_dim=X['Rango_Horario_Consulta_int'].nunique(), output_dim=embedding_dim)(input_rango_horario)
    embedding_salida = Embedding(input_dim=X['Hora_Salida_Rango_int'].nunique(), output_dim=embedding_dim)(input_salida)
    embedding_llegada = Embedding(input_dim=X['Hora_Llegada_Rango_int'].nunique(), output_dim=embedding_dim)(input_llegada)

    features_reshaped = Reshape((1, 3))(features)
    x = Concatenate()([embedding_origen, embedding_destino, embedding_rango_horario,
                       embedding_salida, embedding_llegada, features_reshaped])

    x = TCN(nb_filters=tcn_filters, return_sequences=False)(x)
    x = Dense(dense_units, activation='relu')(x)
    x = Dense(1)(x)

    model_tcn = Model(inputs=[input_origen, input_destino, input_rango_horario,
                              input_salida, input_llegada, features], outputs=x)
    model_tcn.compile(optimizer=Adam(learning_rate=learning_rate), loss='mse')

    model_tcn.fit([X_train['Origen_int'], X_train['Destino_int'], X_train['Rango_Horario_Consulta_int'],
                   X_train['Hora_Salida_Rango_int'], X_train['Hora_Llegada_Rango_int'],
                   X_train[['Duracion_minutos', 'Directo_binario', 'Dias_hasta_vuelo']].values],
                  y_train, epochs=100, batch_size=32, verbose=0)

    y_pred = model_tcn.predict([X_val['Origen_int'], X_val['Destino_int'], X_val['Rango_Horario_Consulta_int'],
                                X_val['Hora_Salida_Rango_int'], X_val['Hora_Llegada_Rango_int'],
                                X_val[['Duracion_minutos', 'Directo_binario', 'Dias_hasta_vuelo']].values])

    rmse_tcn = np.sqrt(mean_squared_error(y_val, y_pred))
    return rmse_tcn

# Optimizaci贸n con un solo trial
study_tcn = optuna.create_study(direction='minimize')
study_tcn.optimize(objective_tcn, n_trials=10)

print("Best parameters TCN:", study_tcn.best_params)

# Entrenamiento final con mejores hiperpar谩metros
start_time = time.time()
best_params = study_tcn.best_params
embedding_dim = best_params['embedding_dim']
tcn_filters = best_params['tcn_filters']
dense_units = best_params['dense_units']
learning_rate = best_params['learning_rate']

train_size = int(0.8 * len(X))
X_train, X_val = X.iloc[:train_size], X.iloc[train_size:]
y_train, y_val = y.iloc[:train_size], y.iloc[train_size:]

input_origen = Input(shape=(1,))
input_destino = Input(shape=(1,))
input_rango_horario = Input(shape=(1,))
input_salida = Input(shape=(1,))
input_llegada = Input(shape=(1,))
features = Input(shape=(3,))

embedding_origen = Embedding(input_dim=X['Origen_int'].nunique(), output_dim=embedding_dim)(input_origen)
embedding_destino = Embedding(input_dim=X['Destino_int'].nunique(), output_dim=embedding_dim)(input_destino)
embedding_rango_horario = Embedding(input_dim=X['Rango_Horario_Consulta_int'].nunique(), output_dim=embedding_dim)(input_rango_horario)
embedding_salida = Embedding(input_dim=X['Hora_Salida_Rango_int'].nunique(), output_dim=embedding_dim)(input_salida)
embedding_llegada = Embedding(input_dim=X['Hora_Llegada_Rango_int'].nunique(), output_dim=embedding_dim)(input_llegada)

features_reshaped = Reshape((1, 3))(features)
x = Concatenate()([embedding_origen, embedding_destino, embedding_rango_horario,
                   embedding_salida, embedding_llegada, features_reshaped])

x = TCN(nb_filters=tcn_filters, return_sequences=False)(x)
x = Dense(dense_units, activation='relu')(x)
x = Dense(1)(x)

model_tcn = Model(inputs=[input_origen, input_destino, input_rango_horario,
                          input_salida, input_llegada, features], outputs=x)
model_tcn.compile(optimizer=Adam(learning_rate=learning_rate), loss='mse')

model_tcn.fit([X_train['Origen_int'], X_train['Destino_int'], X_train['Rango_Horario_Consulta_int'],
               X_train['Hora_Salida_Rango_int'], X_train['Hora_Llegada_Rango_int'],
               X_train[['Duracion_minutos', 'Directo_binario', 'Dias_hasta_vuelo']].values],
              y_train, epochs=100, batch_size=32, verbose=0)

y_pred = model_tcn.predict([X_val['Origen_int'], X_val['Destino_int'], X_val['Rango_Horario_Consulta_int'],
                            X_val['Hora_Salida_Rango_int'], X_val['Hora_Llegada_Rango_int'],
                            X_val[['Duracion_minutos', 'Directo_binario', 'Dias_hasta_vuelo']].values])

final_metrics_tcn_obj1E = {
    'MAE': mean_absolute_error(y_val, y_pred),
    'MSE': mean_squared_error(y_val, y_pred),
    'RMSE': np.sqrt(mean_squared_error(y_val, y_pred)),
    'R2': r2_score(y_val, y_pred),
    'Training_Time': time.time() - start_time,
    'Best_Params': str(best_params)
}

print("\nPromedios finales de las m茅tricas TCN:")
print(pd.Series(final_metrics_tcn_obj1E))

"""## **MODELO 4: TRANSFORMERS**

Mecanismo de Atenci贸n:

Utilizan un mecanismo de atenci贸n que permite a la red enfocarse en diferentes partes de la entrada de manera din谩mica.
"""

import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Embedding, Dense, Flatten, Input, Concatenate, Dropout, Reshape
from tensorflow.keras.optimizers import Adam
from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error
from sklearn.preprocessing import StandardScaler
import optuna
import time

# Normalizaci贸n y preparaci贸n de datos
X = df[['Origen_int', 'Destino_int', 'Duracion_minutos', 'Directo_binario',
        'Dias_hasta_vuelo', 'Rango_Horario_Consulta_int', 'Hora_Salida_Rango_int', 'Hora_Llegada_Rango_int']]
y = df['Tarifa']

scaler = StandardScaler()
X[['Duracion_minutos', 'Dias_hasta_vuelo']] = X[['Duracion_minutos', 'Dias_hasta_vuelo']].astype(float)
X[['Duracion_minutos', 'Dias_hasta_vuelo']] = scaler.fit_transform(X[['Duracion_minutos', 'Dias_hasta_vuelo']])

# Dividir una vez (80/20) para entrenamiento y validaci贸n
split_index = int(len(X) * 0.8)
X_train, X_val = X.iloc[:split_index], X.iloc[split_index:]
y_train, y_val = y.iloc[:split_index], y.iloc[split_index:]

# Optuna
def objective(trial):
    embedding_dim = trial.suggest_categorical("embedding_dim", [4, 8, 16])
    num_heads = trial.suggest_int('num_heads', 2, 8)
    ff_dim = trial.suggest_int('ff_dim', 32, 128)
    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)
    learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-2, log=True)

    input_origen = Input(shape=(1,))
    input_destino = Input(shape=(1,))
    input_rango_horario = Input(shape=(1,))
    input_salida = Input(shape=(1,))
    input_llegada = Input(shape=(1,))
    features = Input(shape=(3,))

    embedding_origen = Embedding(input_dim=X['Origen_int'].nunique(), output_dim=embedding_dim)(input_origen)
    embedding_destino = Embedding(input_dim=X['Destino_int'].nunique(), output_dim=embedding_dim)(input_destino)
    embedding_rango_horario = Embedding(input_dim=X['Rango_Horario_Consulta_int'].nunique(), output_dim=embedding_dim)(input_rango_horario)
    embedding_salida = Embedding(input_dim=X['Hora_Salida_Rango_int'].nunique(), output_dim=embedding_dim)(input_salida)
    embedding_llegada = Embedding(input_dim=X['Hora_Llegada_Rango_int'].nunique(), output_dim=embedding_dim)(input_llegada)

    features_reshaped = Reshape((1, 3))(features)

    x = Concatenate(axis=2)([embedding_origen, embedding_destino, embedding_rango_horario,
                             embedding_salida, embedding_llegada, features_reshaped])
    x = Flatten()(x)
    ffn = Dense(ff_dim, activation='relu')(x)
    ffn = Dropout(dropout_rate)(ffn)
    ffn = Dense(1)(ffn)

    model = Model(inputs=[input_origen, input_destino, input_rango_horario,
                          input_salida, input_llegada, features], outputs=ffn)
    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mse')

    model.fit([X_train['Origen_int'], X_train['Destino_int'], X_train['Rango_Horario_Consulta_int'],
               X_train['Hora_Salida_Rango_int'], X_train['Hora_Llegada_Rango_int'],
               X_train[['Duracion_minutos', 'Directo_binario', 'Dias_hasta_vuelo']].values],
              y_train, epochs=100, batch_size=32, verbose=0)

    y_pred = model.predict([X_val['Origen_int'], X_val['Destino_int'], X_val['Rango_Horario_Consulta_int'],
                            X_val['Hora_Salida_Rango_int'], X_val['Hora_Llegada_Rango_int'],
                            X_val[['Duracion_minutos', 'Directo_binario', 'Dias_hasta_vuelo']].values])

    return np.sqrt(mean_squared_error(y_val, y_pred))

# Optuna run con 1 trial
study = optuna.create_study(direction='minimize')
study.optimize(objective, n_trials=10)

# Evaluaci贸n final con mejores hiperpar谩metros
best_params = study.best_params
embedding_dim = best_params['embedding_dim']
ff_dim = best_params['ff_dim']
dropout_rate = best_params['dropout_rate']
learning_rate = best_params['learning_rate']

start_time = time.time()

input_origen = Input(shape=(1,))
input_destino = Input(shape=(1,))
input_rango_horario = Input(shape=(1,))
input_salida = Input(shape=(1,))
input_llegada = Input(shape=(1,))
features = Input(shape=(3,))

embedding_origen = Embedding(input_dim=X['Origen_int'].nunique(), output_dim=embedding_dim)(input_origen)
embedding_destino = Embedding(input_dim=X['Destino_int'].nunique(), output_dim=embedding_dim)(input_destino)
embedding_rango_horario = Embedding(input_dim=X['Rango_Horario_Consulta_int'].nunique(), output_dim=embedding_dim)(input_rango_horario)
embedding_salida = Embedding(input_dim=X['Hora_Salida_Rango_int'].nunique(), output_dim=embedding_dim)(input_salida)
embedding_llegada = Embedding(input_dim=X['Hora_Llegada_Rango_int'].nunique(), output_dim=embedding_dim)(input_llegada)

features_reshaped = Reshape((1, 3))(features)

x = Concatenate(axis=2)([embedding_origen, embedding_destino, embedding_rango_horario,
                         embedding_salida, embedding_llegada, features_reshaped])
x = Flatten()(x)
ffn = Dense(ff_dim, activation='relu')(x)
ffn = Dropout(dropout_rate)(ffn)
ffn = Dense(1)(ffn)

model = Model(inputs=[input_origen, input_destino, input_rango_horario,
                      input_salida, input_llegada, features], outputs=ffn)
model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mse')

model.fit([X_train['Origen_int'], X_train['Destino_int'], X_train['Rango_Horario_Consulta_int'],
           X_train['Hora_Salida_Rango_int'], X_train['Hora_Llegada_Rango_int'],
           X_train[['Duracion_minutos', 'Directo_binario', 'Dias_hasta_vuelo']].values],
          y_train, epochs=100, batch_size=32, verbose=0)

y_pred = model.predict([X_val['Origen_int'], X_val['Destino_int'], X_val['Rango_Horario_Consulta_int'],
                        X_val['Hora_Salida_Rango_int'], X_val['Hora_Llegada_Rango_int'],
                        X_val[['Duracion_minutos', 'Directo_binario', 'Dias_hasta_vuelo']].values])

# M茅tricas finales
final_metrics_transformer_obj1E = pd.Series({
    'MAE': mean_absolute_error(y_val, y_pred),
    'MSE': mean_squared_error(y_val, y_pred),
    'RMSE': np.sqrt(mean_squared_error(y_val, y_pred)),
    'R2': r2_score(y_val, y_pred),
    'Training_Time': time.time() - start_time,
    'Best_Params': str(study.best_params)
})

print("Promedios finales de las m茅tricas Transformer:")
print(final_metrics_transformer_obj1E)

"""## **XGBOOST**"""

import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error
import optuna
import numpy as np
import matplotlib.pyplot as plt
import time
import pandas as pd

# Leer dataset con embeddings entrenados para Tarifa
df_tarifa = pd.read_csv("embed_tarifa.csv")

# Separar caracter铆sticas (X) y objetivo (y)
X = df_tarifa.drop(columns=['Tarifa'])
y = df_tarifa['Tarifa']

# Divisi贸n fija para todo el proceso
X_train_full, X_val_full, y_train_full, y_val_full = train_test_split(X, y, test_size=0.2, random_state=42)

# Optuna para encontrar los mejores hiperpar谩metros
def objective(trial):
    params = {
        'n_estimators': trial.suggest_int('n_estimators', 50, 100),
        'max_depth': trial.suggest_int('max_depth', 3, 10),
        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),
        'subsample': trial.suggest_float('subsample', 0.5, 1.0),
        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),
        'gamma': trial.suggest_float('gamma', 0, 5),
        'reg_alpha': trial.suggest_float('reg_alpha', 0, 1.0),
        'reg_lambda': trial.suggest_float('reg_lambda', 0, 1.0)
    }

    model = xgb.XGBRegressor(**params, random_state=42, verbosity=0)
    model.fit(X_train_full, y_train_full)

    y_pred = model.predict(X_val_full)
    rmse = np.sqrt(mean_squared_error(y_val_full, y_pred))
    return rmse

# Tiempo de ejecuci贸n para la optimizaci贸n
opt_start_time = time.time()
study = optuna.create_study(direction="minimize")
study.optimize(objective, n_trials=10)
opt_time = time.time() - opt_start_time

print("Best parameters:", study.best_params)
print(f"Tiempo de optimizaci贸n: {opt_time:.2f} segundos")

# Entrenamiento final con mejores par谩metros
best_params = study.best_params
model_xgboost = xgb.XGBRegressor(**best_params, random_state=42, verbosity=0)

start_training_time = time.time()
model_xgboost.fit(X_train_full, y_train_full)
y_pred = model_xgboost.predict(X_val_full)
training_time = time.time() - start_training_time

# M茅tricas
mae = mean_absolute_error(y_val_full, y_pred)
mse = mean_squared_error(y_val_full, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_val_full, y_pred)

# Resultados finales
final_metrics_xgb_obj1E = pd.Series({
    'MAE': mae,
    'MSE': mse,
    'RMSE': rmse,
    'R2': r2,
    'Training_Time': training_time,
    'Best_Params': str(best_params)
})

print("\n Resultados finales del modelo XGBoost (sin TimeSeriesSplit):")
print(final_metrics_xgb_obj1E)

"""## **MODELO 6: KNN**"""

from sklearn.neighbors import KNeighborsRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error
import optuna
import numpy as np
import pandas as pd
import time

# Leer el archivo con embeddings entrenados para obj1
df_tarifa = pd.read_csv("embed_tarifa.csv")

# Separar caracter铆sticas (X) y variable objetivo (y)
X = df_tarifa.drop(columns=['Tarifa'])
y = df_tarifa['Tarifa']

# Divisi贸n en entrenamiento y validaci贸n (80%-20%)
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)

# Optuna para encontrar los mejores hiperpar谩metros
def objective(trial):
    params = {
        'n_neighbors': trial.suggest_int('n_neighbors', 3, 15),
        'weights': trial.suggest_categorical('weights', ['uniform', 'distance']),
        'p': trial.suggest_int('p', 1, 2)
    }

    model = KNeighborsRegressor(**params)
    model.fit(X_train, y_train)

    y_pred = model.predict(X_val)
    rmse = np.sqrt(mean_squared_error(y_val, y_pred))

    return rmse

# Tiempo de optimizaci贸n
opt_start_time = time.time()
study = optuna.create_study(direction="minimize")
study.optimize(objective, n_trials=10)
opt_time = time.time() - opt_start_time

print("Best parameters:", study.best_params)
print(f"Tiempo de optimizaci贸n: {opt_time:.2f} segundos")

# Evaluaci贸n con los mejores par谩metros
best_params = study.best_params
model_knn = KNeighborsRegressor(**best_params)

start_training_time = time.time()
model_knn.fit(X_train, y_train)
y_pred = model_knn.predict(X_val)
training_time = time.time() - start_training_time

# M茅tricas finales
mae = mean_absolute_error(y_val, y_pred)
mse = mean_squared_error(y_val, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_val, y_pred)

final_metrics_knn_obj1E = {
    'MAE': mae,
    'MSE': mse,
    'RMSE': rmse,
    'R2': r2,
    'Training_Time': training_time,
    'Best_Params': str(best_params)
}

print("\n M茅tricas finales (KNN obj1E con embeddings):")
print(final_metrics_knn_obj1E)

"""## **MODELO 7: ARBOL DE DESICION**"""

import pandas as pd
import numpy as np
from sklearn.tree import DecisionTreeRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error
import optuna
import time

# Leer el dataset con embeddings para el objetivo 1
df = pd.read_csv("embed_tarifa.csv")

# Definir variables predictoras (todas las columnas excepto la salida)
X = df.drop(columns=["Tarifa"])
y = df["Tarifa"]

# Divisi贸n en entrenamiento y validaci贸n (80%-20%)
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)

# Funci贸n objetivo para Optuna
def objective(trial):
    params = {
        "max_depth": trial.suggest_int("max_depth", 3, 20),
        "min_samples_split": trial.suggest_int("min_samples_split", 2, 10),
        "min_samples_leaf": trial.suggest_int("min_samples_leaf", 1, 10),
        "max_features": trial.suggest_categorical("max_features", ["sqrt", "log2", None])
    }

    model = DecisionTreeRegressor(**params)
    model.fit(X_train, y_train)
    y_pred = model.predict(X_val)

    rmse = np.sqrt(mean_squared_error(y_val, y_pred))
    return rmse

# Ejecutar Optuna para optimizaci贸n
opt_start_time = time.time()
study = optuna.create_study(direction="minimize")
study.optimize(objective, n_trials=10)
opt_time = time.time() - opt_start_time

print("Best parameters:", study.best_params)
print(f"Tiempo de optimizaci贸n: {opt_time:.2f} segundos")

# Entrenar modelo con mejores hiperpar谩metros
best_params = study.best_params
model_tree = DecisionTreeRegressor(**best_params)

start_training_time = time.time()
model_tree.fit(X_train, y_train)
y_pred = model_tree.predict(X_val)
training_time = time.time() - start_training_time

# Calcular m茅tricas
mae = mean_absolute_error(y_val, y_pred)
mse = mean_squared_error(y_val, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_val, y_pred)

# Guardar m茅tricas finales
final_metrics_tree_obj1E = {
    "MAE": mae,
    "MSE": mse,
    "RMSE": rmse,
    "R2": r2,
    "Training_Time": training_time,
    "Best_Params": str(best_params)
}

# Mostrar resultados
print("\n M茅tricas finales (rbol de Decisi贸n obj1E con embeddings):")
print(final_metrics_tree_obj1E)

"""## **RANDOM FOREST**"""

import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error
import optuna
import time

# Cargar los embeddings entrenados para la variable Tarifa
df_tarifa = pd.read_csv("embed_tarifa.csv")

# Separar variables predictoras y objetivo
X = df_tarifa.drop(columns=["Tarifa"])
y = df_tarifa["Tarifa"]

# Divisi贸n simple de datos
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)

# Funci贸n objetivo para Optuna
def objective(trial):
    params = {
        'n_estimators': trial.suggest_int('n_estimators', 50, 100),
        'max_depth': trial.suggest_int('max_depth', 5, 20),
        'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),
        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),
        'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2', None])
    }

    model = RandomForestRegressor(**params, random_state=42)
    model.fit(X_train, y_train)
    y_pred = model.predict(X_val)

    rmse = np.sqrt(mean_squared_error(y_val, y_pred))
    return rmse

# Optimizaci贸n con Optuna
opt_start_time = time.time()
study = optuna.create_study(direction="minimize")
study.optimize(objective, n_trials=10)
opt_time = time.time() - opt_start_time

print("Best parameters:", study.best_params)
print(f"Tiempo de optimizaci贸n: {opt_time:.2f} segundos")

# Entrenamiento final con mejores hiperpar谩metros
best_params = study.best_params
model_rf = RandomForestRegressor(**best_params, random_state=42)

start_training_time = time.time()
model_rf.fit(X_train, y_train)
y_pred = model_rf.predict(X_val)
training_time = time.time() - start_training_time

# C谩lculo de m茅tricas
mae = mean_absolute_error(y_val, y_pred)
mse = mean_squared_error(y_val, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_val, y_pred)

# Guardar m茅tricas finales
final_metrics_rf_obj1E = {
    "MAE": mae,
    "MSE": mse,
    "RMSE": rmse,
    "R2": r2,
    "Training_Time": training_time,
    "Best_Params": str(best_params)
}

# Mostrar resultados
print("\n M茅tricas finales (Random Forest obj1E con embeddings):")
print(final_metrics_rf_obj1E)

"""## **RESULTADOS OBJETIVO 1**"""

import pandas as pd

# --- Lista de nombres de los modelos
model_names = [
    "LSTM",
    "GRU",
    "TCN",
    "Transformer",
    "XGBoost",
    "KNN",
    "Decision Tree",
    "Random Forest"
]

# --- Resultados de cada modelo (deben ser diccionarios)
obj1_results_E = [
    final_metrics_lstm_obj1E,
    final_gru_metrics_obj1E,
    final_metrics_tcn_obj1E,
    final_metrics_transformer_obj1E,
    final_metrics_xgb_obj1E,
    final_metrics_knn_obj1E,
    final_metrics_tree_obj1E,
    final_metrics_rf_obj1E
]

# --- Combinar nombres y resultados
resultados_con_nombres = []
for name, metrics in zip(model_names, obj1_results_E):
    resultados_con_nombres.append({'Modelo': name, **metrics})

# --- Crear DataFrame
df_resultados = pd.DataFrame(resultados_con_nombres)

# --- Guardar en CSV
df_resultados.to_csv("resultados_objetivo1_E.csv", index=False)

# --- Mostrar tabla
print("\n Tabla de resultados combinados:")
print(df_resultados)

"""# **EJECUCION MULTIOUTPUT**

## **LSTM**
"""

# Importar las librer铆as necesarias
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Cargar el dataset
df = pd.read_csv('flights_data_final.csv')

# Mostrar las primeras filas
print("Primeras 5 filas del dataset:")
display(df.head())

# --- LSTM Multioutput con Optuna y embeddings como hiperpar谩metro ---
import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Concatenate, Flatten, Lambda, Dropout
from tensorflow.keras.optimizers import Adam
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, accuracy_score, precision_score, recall_score, f1_score
import time
import optuna

# ----------------------------
# Dataset y preprocesamiento
# ----------------------------

# Variables independientes (sin incluir y_range)
X = df[['Origen_int', 'Destino_int', 'Duracion_minutos', 'Directo_binario',
        'Hora_Salida_Rango_int', 'Hora_Llegada_Rango_int']]

# Variables objetivo
y_price = df['Tarifa']
y_days = df['Dias_hasta_vuelo']
y_range = df['Rango_Horario_Consulta_int']

# Split
X_train, X_val, y_price_train, y_price_val, y_days_train, y_days_val, y_range_train, y_range_val = train_test_split(
    X, y_price, y_days, y_range, test_size=0.2, random_state=42)

# Copia para modificar
X_train = X_train.copy()
X_val = X_val.copy()

# Normalizaci贸n de la variable continua
scaler = StandardScaler()
X_train[['Duracion_minutos']] = scaler.fit_transform(X_train[['Duracion_minutos']])
X_val[['Duracion_minutos']] = scaler.transform(X_val[['Duracion_minutos']])

# ----------------------------
# Modelo multitarea LSTM
# ----------------------------

def create_model(embedding_dim, learning_rate, lstm_units, dropout_rate):
    input_origen = Input(shape=(1,), name='input_origen')
    input_destino = Input(shape=(1,), name='input_destino')
    input_salida = Input(shape=(1,), name='input_salida')
    input_llegada = Input(shape=(1,), name='input_llegada')
    input_features = Input(shape=(2,), name='input_features')  # Duraci贸n + Directo

    # Embeddings
    embedding_origen = Embedding(input_dim=X['Origen_int'].nunique() + 1, output_dim=embedding_dim)(input_origen)
    embedding_destino = Embedding(input_dim=X['Destino_int'].nunique() + 1, output_dim=embedding_dim)(input_destino)
    embedding_salida = Embedding(input_dim=X['Hora_Salida_Rango_int'].nunique() + 1, output_dim=embedding_dim)(input_salida)
    embedding_llegada = Embedding(input_dim=X['Hora_Llegada_Rango_int'].nunique() + 1, output_dim=embedding_dim)(input_llegada)

    # Concatenaci贸n
    x = Concatenate()([
        Flatten()(embedding_origen),
        Flatten()(embedding_destino),
        Flatten()(embedding_salida),
        Flatten()(embedding_llegada),
        input_features
    ])

    x = Lambda(lambda x: tf.expand_dims(x, axis=1))(x)
    x = LSTM(lstm_units, return_sequences=False)(x)
    x = Dropout(dropout_rate)(x)

    # Salidas
    price_output = Dense(64, activation='relu')(x)
    price_output = Dense(1, name='price_output')(price_output)

    days_output = Dense(64, activation='relu')(x)
    days_output = Dense(1, name='days_output')(days_output)

    range_output = Dense(64, activation='relu')(x)
    range_output = Dense(y_range.nunique(), activation='softmax', name='range_output')(range_output)

    model = Model(inputs=[input_origen, input_destino, input_salida, input_llegada, input_features],
                  outputs=[price_output, days_output, range_output])

    model.compile(optimizer=Adam(learning_rate=learning_rate),
                  loss={'price_output': 'mse', 'days_output': 'mse', 'range_output': 'sparse_categorical_crossentropy'},
                  metrics={'price_output': 'mae', 'days_output': 'mae', 'range_output': 'accuracy'})
    return model

# ----------------------------
# Optuna tuning
# ----------------------------

def objective(trial):
    embedding_dim = trial.suggest_int('embedding_dim', 4, 16)
    lr = trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True)
    units = trial.suggest_int('lstm_units', 32, 128)
    drop = trial.suggest_float('dropout_rate', 0.2, 0.5)

    model = create_model(embedding_dim, lr, units, drop)

    model.fit([
        X_train['Origen_int'], X_train['Destino_int'],
        X_train['Hora_Salida_Rango_int'], X_train['Hora_Llegada_Rango_int'],
        X_train[['Duracion_minutos', 'Directo_binario']].values
    ],
    [y_price_train, y_days_train, y_range_train],
    epochs=100, batch_size=32, verbose=0)

    y_pred_price, y_pred_days, _ = model.predict([
        X_val['Origen_int'], X_val['Destino_int'],
        X_val['Hora_Salida_Rango_int'], X_val['Hora_Llegada_Rango_int'],
        X_val[['Duracion_minutos', 'Directo_binario']].values
    ])

    return mean_absolute_error(y_price_val, y_pred_price) + mean_absolute_error(y_days_val, y_pred_days)

# Ejecutar Optuna
study = optuna.create_study(direction='minimize')
study.optimize(objective, n_trials=10)  # puedes ajustar n_trials

# ----------------------------
# Entrenamiento final
# ----------------------------

best = study.best_params
model = create_model(best['embedding_dim'], best['learning_rate'], best['lstm_units'], best['dropout_rate'])

start_train = time.time()
model.fit([
    X_train['Origen_int'], X_train['Destino_int'],
    X_train['Hora_Salida_Rango_int'], X_train['Hora_Llegada_Rango_int'],
    X_train[['Duracion_minutos', 'Directo_binario']].values
], [y_price_train, y_days_train, y_range_train], epochs=100, batch_size=32, verbose=0)
end_train = time.time()

# ----------------------------
# Evaluaci贸n
# ----------------------------

y_price_pred, y_days_pred, y_range_pred = model.predict([
    X_val['Origen_int'], X_val['Destino_int'],
    X_val['Hora_Salida_Rango_int'], X_val['Hora_Llegada_Rango_int'],
    X_val[['Duracion_minutos', 'Directo_binario']].values
])

results_multi_lstm_E = pd.DataFrame([{
    'Modelo': 'LSTM (Embeddings)',
    'MAE_Tarifa': mean_absolute_error(y_price_val, y_price_pred),
    'MSE_Tarifa': mean_squared_error(y_price_val, y_price_pred),
    'RMSE_Tarifa': np.sqrt(mean_squared_error(y_price_val, y_price_pred)),
    'R2_Tarifa': r2_score(y_price_val, y_price_pred),

    'MAE_DiasAnt': mean_absolute_error(y_days_val, y_days_pred),
    'MSE_DiasAnt': mean_squared_error(y_days_val, y_days_pred),
    'RMSE_DiasAnt': np.sqrt(mean_squared_error(y_days_val, y_days_pred)),
    'R2_DiasAnt': r2_score(y_days_val, y_days_pred),

    'Accuracy_Rango': accuracy_score(y_range_val, np.argmax(y_range_pred, axis=1)),
    'Precision_Rango': precision_score(y_range_val, np.argmax(y_range_pred, axis=1), average='weighted'),
    'Recall_Rango': recall_score(y_range_val, np.argmax(y_range_pred, axis=1), average='weighted'),
    'F1_Rango': f1_score(y_range_val, np.argmax(y_range_pred, axis=1), average='weighted'),

    'Training_time': end_train - start_train,
}])
results_multi_lstm_E['Best_Params'] = [str(best)]
print(results_multi_lstm_E)

"""## **GRU**"""

import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Embedding, GRU, Dense, Concatenate, Flatten, Lambda, Dropout
from tensorflow.keras.optimizers import Adam
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, accuracy_score, precision_score, recall_score, f1_score
import optuna
import time

# Variables predictoras (sin incluir las variables objetivo)
X = df[['Origen_int', 'Destino_int', 'Duracion_minutos', 'Directo_binario', 'Hora_Salida_Rango_int', 'Hora_Llegada_Rango_int']]
y_price = df['Tarifa']
y_days = df['Dias_hasta_vuelo']
y_range = df['Rango_Horario_Consulta_int']

# Divisi贸n del dataset
X_train, X_val, y_price_train, y_price_val, y_days_train, y_days_val, y_range_train, y_range_val = train_test_split(
    X, y_price, y_days, y_range, test_size=0.2, random_state=42
)

# Normalizaci贸n
scaler = StandardScaler()
X_train[['Duracion_minutos']] = scaler.fit_transform(X_train[['Duracion_minutos']])
X_val[['Duracion_minutos']] = scaler.transform(X_val[['Duracion_minutos']])

# Funci贸n para crear el modelo GRU
def create_gru_model(embedding_dim, learning_rate, gru_units, dropout_rate):
    input_origen = Input(shape=(1,), name='input_origen')
    input_destino = Input(shape=(1,), name='input_destino')
    input_salida = Input(shape=(1,), name='input_salida')
    input_llegada = Input(shape=(1,), name='input_llegada')
    input_features = Input(shape=(2,), name='input_features')  # Duracion_minutos, Directo_binario

    emb_origen = Embedding(input_dim=df['Origen_int'].nunique(), output_dim=embedding_dim)(input_origen)
    emb_destino = Embedding(input_dim=df['Destino_int'].nunique(), output_dim=embedding_dim)(input_destino)
    emb_salida = Embedding(input_dim=df['Hora_Salida_Rango_int'].nunique(), output_dim=embedding_dim)(input_salida)
    emb_llegada = Embedding(input_dim=df['Hora_Llegada_Rango_int'].nunique(), output_dim=embedding_dim)(input_llegada)

    x = Concatenate()([
        Flatten()(emb_origen), Flatten()(emb_destino),
        Flatten()(emb_salida), Flatten()(emb_llegada),
        input_features
    ])
    x = Lambda(lambda x: tf.expand_dims(x, axis=1))(x)
    x = GRU(gru_units, return_sequences=False)(x)
    x = Dropout(dropout_rate)(x)

    # Salidas
    price_output = Dense(64, activation='relu')(x)
    price_output = Dense(1, name='price_output')(price_output)

    days_output = Dense(64, activation='relu')(x)
    days_output = Dense(1, name='days_output')(days_output)

    range_output = Dense(64, activation='relu')(x)
    range_output = Dense(df['Rango_Horario_Consulta_int'].nunique(), activation='softmax', name='range_output')(range_output)

    model = Model(
        inputs=[input_origen, input_destino, input_salida, input_llegada, input_features],
        outputs=[price_output, days_output, range_output]
    )

    model.compile(
        optimizer=Adam(learning_rate=learning_rate),
        loss={
            'price_output': 'mse',
            'days_output': 'mse',
            'range_output': 'sparse_categorical_crossentropy'
        },
        metrics={
            'price_output': 'mae',
            'days_output': 'mae',
            'range_output': 'accuracy'
        }
    )

    return model

# Optuna
def objective(trial):
    embedding_dim = trial.suggest_int('embedding_dim', 4, 16)
    lr = trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True)
    units = trial.suggest_int('gru_units', 32, 128)
    drop = trial.suggest_float('dropout_rate', 0.2, 0.5)

    model = create_gru_model(embedding_dim, lr, units, drop)

    model.fit(
        [X_train['Origen_int'], X_train['Destino_int'],
         X_train['Hora_Salida_Rango_int'], X_train['Hora_Llegada_Rango_int'],
         X_train[['Duracion_minutos', 'Directo_binario']]],
        [y_price_train, y_days_train, y_range_train],
        validation_data=(
            [X_val['Origen_int'], X_val['Destino_int'],
             X_val['Hora_Salida_Rango_int'], X_val['Hora_Llegada_Rango_int'],
             X_val[['Duracion_minutos', 'Directo_binario']]],
            [y_price_val, y_days_val, y_range_val]),
        epochs=100,
        batch_size=32,
        verbose=0
    )

    preds = model.predict([
        X_val['Origen_int'], X_val['Destino_int'],
        X_val['Hora_Salida_Rango_int'], X_val['Hora_Llegada_Rango_int'],
        X_val[['Duracion_minutos', 'Directo_binario']]
    ], verbose=0)
    return mean_absolute_error(y_price_val, preds[0]) + mean_absolute_error(y_days_val, preds[1])

# Optimizaci贸n
start_optuna = time.time()
study = optuna.create_study(direction='minimize')
study.optimize(objective, n_trials=10)
optuna_time = time.time() - start_optuna

# Entrenamiento final con mejores hiperpar谩metros
best_params = study.best_params
model = create_gru_model(best_params['embedding_dim'], best_params['learning_rate'],
                         best_params['gru_units'], best_params['dropout_rate'])

start_train = time.time()
model.fit(
    [X_train['Origen_int'], X_train['Destino_int'],
     X_train['Hora_Salida_Rango_int'], X_train['Hora_Llegada_Rango_int'],
     X_train[['Duracion_minutos', 'Directo_binario']]],
    [y_price_train, y_days_train, y_range_train],
    epochs=100,
    batch_size=32,
    verbose=1
)
train_time = time.time() - start_train

# Evaluaci贸n final
y_price_pred, y_days_pred, y_range_pred = model.predict([
    X_val['Origen_int'], X_val['Destino_int'],
    X_val['Hora_Salida_Rango_int'], X_val['Hora_Llegada_Rango_int'],
    X_val[['Duracion_minutos', 'Directo_binario']]
], verbose=0)
y_range_classes = np.argmax(y_range_pred, axis=1)

# M茅tricas
results_multi_gru_E = pd.DataFrame([{
    'Modelo': 'GRU',
    'MAE_Tarifa': mean_absolute_error(y_price_val, y_price_pred),
    'MSE_Tarifa': mean_squared_error(y_price_val, y_price_pred),
    'RMSE_Tarifa': np.sqrt(mean_squared_error(y_price_val, y_price_pred)),
    'R2_Tarifa': r2_score(y_price_val, y_price_pred),

    'MAE_DiasAnt': mean_absolute_error(y_days_val, y_days_pred),
    'MSE_DiasAnt': mean_squared_error(y_days_val, y_days_pred),
    'RMSE_DiasAnt': np.sqrt(mean_squared_error(y_days_val, y_days_pred)),
    'R2_DiasAnt': r2_score(y_days_val, y_days_pred),

    'Accuracy_Rango': accuracy_score(y_range_val, y_range_classes),
    'Precision_Rango': precision_score(y_range_val, y_range_classes, average='weighted', zero_division=0),
    'Recall_Rango': recall_score(y_range_val, y_range_classes, average='weighted', zero_division=0),
    'F1_Rango': f1_score(y_range_val, y_range_classes, average='weighted', zero_division=0),
    'Training_time': train_time,
    'Best_Params': str(best_params)
}])

print(results_multi_gru_E)

"""## **TCN**"""

import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Embedding, Dense, Concatenate, Flatten, Lambda
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error, accuracy_score, precision_score, recall_score, f1_score
from tcn import TCN
import optuna
import time

# Variables predictoras excluyendo la variable objetivo 'Rango_Horario_Consulta_int'
X = df[['Origen_int', 'Destino_int', 'Duracion_minutos', 'Directo_binario', 'Hora_Salida_Rango_int', 'Hora_Llegada_Rango_int']]
y_price = df['Tarifa']
y_days = df['Dias_hasta_vuelo']
y_range = df['Rango_Horario_Consulta_int']

X_train, X_val, y_price_train, y_price_val, y_days_train, y_days_val, y_range_train, y_range_val = train_test_split(
    X, y_price, y_days, y_range, test_size=0.2, random_state=42)

# Escalado de variables num茅ricas
scaler = StandardScaler()
X_train[['Duracion_minutos']] = scaler.fit_transform(X_train[['Duracion_minutos']])
X_val[['Duracion_minutos']] = scaler.transform(X_val[['Duracion_minutos']])

# Funci贸n para crear el modelo TCN multitarea
def create_tcn_model(trial):
    embedding_dim = trial.suggest_int('embedding_dim', 4, 16)
    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True)
    tcn_filters = trial.suggest_int('tcn_filters', 32, 128)
    kernel_size = trial.suggest_int('kernel_size', 2, 5)
    dropout_rate = trial.suggest_float('dropout_rate', 0.2, 0.5)

    input_origen = Input(shape=(1,), name='input_origen')
    input_destino = Input(shape=(1,), name='input_destino')
    input_salida = Input(shape=(1,), name='input_salida')
    input_llegada = Input(shape=(1,), name='input_llegada')
    input_features = Input(shape=(2,), name='input_features')  # Duraci贸n y Directo

    embedding_origen = Embedding(input_dim=X['Origen_int'].nunique(), output_dim=embedding_dim)(input_origen)
    embedding_destino = Embedding(input_dim=X['Destino_int'].nunique(), output_dim=embedding_dim)(input_destino)
    embedding_salida = Embedding(input_dim=X['Hora_Salida_Rango_int'].nunique(), output_dim=embedding_dim)(input_salida)
    embedding_llegada = Embedding(input_dim=X['Hora_Llegada_Rango_int'].nunique(), output_dim=embedding_dim)(input_llegada)

    x = Concatenate()([
        Flatten()(embedding_origen),
        Flatten()(embedding_destino),
        Flatten()(embedding_salida),
        Flatten()(embedding_llegada),
        input_features
    ])

    x = Lambda(lambda x: tf.expand_dims(x, axis=1))(x)

    x = TCN(nb_filters=tcn_filters, kernel_size=kernel_size, dropout_rate=dropout_rate, return_sequences=False)(x)

    price_output = Dense(64, activation='relu')(x)
    price_output = Dense(1, name='price_output')(price_output)

    days_output = Dense(64, activation='relu')(x)
    days_output = Dense(1, name='days_output')(days_output)

    range_output = Dense(64, activation='relu')(x)
    range_output = Dense(y_range.nunique(), activation='softmax', name='range_output')(range_output)

    model = Model(
        inputs=[input_origen, input_destino, input_salida, input_llegada, input_features],
        outputs=[price_output, days_output, range_output]
    )

    model.compile(
        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),
        loss={
            'price_output': 'mse',
            'days_output': 'mse',
            'range_output': 'sparse_categorical_crossentropy'
        },
        metrics={
            'price_output': 'mae',
            'days_output': 'mae',
            'range_output': 'accuracy'
        }
    )

    return model

# Funci贸n objetivo para Optuna
def objective(trial):
    model = create_tcn_model(trial)

    model.fit(
        [X_train['Origen_int'], X_train['Destino_int'], X_train['Hora_Salida_Rango_int'],
         X_train['Hora_Llegada_Rango_int'], X_train[['Duracion_minutos', 'Directo_binario']].values],
        [y_price_train, y_days_train, y_range_train],
        validation_data=([X_val['Origen_int'], X_val['Destino_int'], X_val['Hora_Salida_Rango_int'],
                          X_val['Hora_Llegada_Rango_int'], X_val[['Duracion_minutos', 'Directo_binario']].values],
                         [y_price_val, y_days_val, y_range_val]),
        epochs=100,
        batch_size=32,
        verbose=0
    )

    y_price_pred, y_days_pred, _ = model.predict(
        [X_val['Origen_int'], X_val['Destino_int'], X_val['Hora_Salida_Rango_int'],
         X_val['Hora_Llegada_Rango_int'], X_val[['Duracion_minutos', 'Directo_binario']].values],
        verbose=0
    )

    return mean_absolute_error(y_price_val, y_price_pred) + mean_absolute_error(y_days_val, y_days_pred)

# Optuna
optuna_start = time.time()
study = optuna.create_study(direction='minimize')
study.optimize(objective, n_trials=10)

# Entrenamiento final
best_params = study.best_params
final_trial = optuna.trial.FixedTrial(best_params)
model_tcn = create_tcn_model(final_trial)

training_start = time.time()
model_tcn.fit(
    [X_train['Origen_int'], X_train['Destino_int'], X_train['Hora_Salida_Rango_int'],
     X_train['Hora_Llegada_Rango_int'], X_train[['Duracion_minutos', 'Directo_binario']].values],
    [y_price_train, y_days_train, y_range_train],
    validation_data=([X_val['Origen_int'], X_val['Destino_int'], X_val['Hora_Salida_Rango_int'],
                      X_val['Hora_Llegada_Rango_int'], X_val[['Duracion_minutos', 'Directo_binario']].values],
                     [y_price_val, y_days_val, y_range_val]),
    epochs=100,
    batch_size=32,
    verbose=1
)
training_end = time.time()

# Evaluaci贸n
y_price_pred, y_days_pred, y_range_pred = model_tcn.predict(
    [X_val['Origen_int'], X_val['Destino_int'], X_val['Hora_Salida_Rango_int'],
     X_val['Hora_Llegada_Rango_int'], X_val[['Duracion_minutos', 'Directo_binario']].values],
    verbose=0
)

y_range_pred_classes = np.argmax(y_range_pred, axis=1)

results_multi_tcn_E = {
    'Modelo': 'TCN',
    'MAE_Tarifa': mean_absolute_error(y_price_val, y_price_pred),
    'R2_Tarifa': r2_score(y_price_val, y_price_pred),
    'RMSE_Tarifa': np.sqrt(mean_squared_error(y_price_val, y_price_pred)),
    'MSE_Tarifa': mean_squared_error(y_price_val, y_price_pred),

    'MAE_DiasAnt': mean_absolute_error(y_days_val, y_days_pred),
    'R2_DiasAnt': r2_score(y_days_val, y_days_pred),
    'RMSE_DiasAnt': np.sqrt(mean_squared_error(y_days_val, y_days_pred)),
    'MSE_DiasAnt': mean_squared_error(y_days_val, y_days_pred),

    'Accuracy_Rango': accuracy_score(y_range_val, y_range_pred_classes),
    'Precision_Rango': precision_score(y_range_val, y_range_pred_classes, average='weighted', zero_division=0),
    'Recall_Rango': recall_score(y_range_val, y_range_pred_classes, average='weighted', zero_division=0),
    'F1_Rango': f1_score(y_range_val, y_range_pred_classes, average='weighted', zero_division=0),

    'Training_time': training_end - training_start,
    'Best_Params': best_params
}

# Resultados
print("\nResultados TCN:")
for k, v in results_multi_tcn_E.items():
    print(f"{k}: {v:.4f}" if isinstance(v, float) else f"{k}: {v}")

"""## **TRANSFORMERS**"""

import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Embedding, Dense, Concatenate, Dropout, LayerNormalization
from tensorflow.keras.layers import MultiHeadAttention, Add, GlobalAveragePooling1D
from tensorflow.keras.optimizers import Adam
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, accuracy_score, precision_score, recall_score, f1_score
import optuna
import time

# Dataset
X = df[['Origen_int', 'Destino_int', 'Duracion_minutos', 'Directo_binario', 'Hora_Salida_Rango_int', 'Hora_Llegada_Rango_int']]
y_price = df['Tarifa']
y_days = df['Dias_hasta_vuelo']
y_range = df['Rango_Horario_Consulta_int']  # Variable objetivo, ya no se incluye en X

X_train, X_val, y_price_train, y_price_val, y_days_train, y_days_val, y_range_train, y_range_val = train_test_split(
    X, y_price, y_days, y_range, test_size=0.2, random_state=42)

# Normalizaci贸n
scaler = StandardScaler()
X_train[['Duracion_minutos']] = scaler.fit_transform(X_train[['Duracion_minutos']])
X_val[['Duracion_minutos']] = scaler.transform(X_val[['Duracion_minutos']])

def transformer_block(x, heads, ff_dim, embedding_dim, dropout_rate):
    attention_output = MultiHeadAttention(num_heads=heads, key_dim=embedding_dim)(x, x)
    attention_output = Dropout(dropout_rate)(attention_output)
    out1 = LayerNormalization(epsilon=1e-6)(Add()([x, attention_output]))
    ffn_output = Dense(ff_dim, activation='relu')(out1)
    ffn_output = Dense(embedding_dim)(ffn_output)
    ffn_output = Dropout(dropout_rate)(ffn_output)
    return LayerNormalization(epsilon=1e-6)(Add()([out1, ffn_output]))

def create_model(embedding_dim, learning_rate, heads, ff_dim, dropout_rate):
    input_origen = Input(shape=(1,), name='input_origen')
    input_destino = Input(shape=(1,), name='input_destino')
    input_salida = Input(shape=(1,), name='input_salida')
    input_llegada = Input(shape=(1,), name='input_llegada')
    input_features = Input(shape=(2,), name='input_features')  # Duraci贸n y binario

    embedding_origen = Embedding(input_dim=X['Origen_int'].nunique(), output_dim=embedding_dim)(input_origen)
    embedding_destino = Embedding(input_dim=X['Destino_int'].nunique(), output_dim=embedding_dim)(input_destino)
    embedding_salida = Embedding(input_dim=X['Hora_Salida_Rango_int'].nunique(), output_dim=embedding_dim)(input_salida)
    embedding_llegada = Embedding(input_dim=X['Hora_Llegada_Rango_int'].nunique(), output_dim=embedding_dim)(input_llegada)

    embeddings = Concatenate(axis=1)([embedding_origen, embedding_destino, embedding_salida, embedding_llegada])
    transformer_output = transformer_block(embeddings, heads=heads, ff_dim=ff_dim, embedding_dim=embedding_dim, dropout_rate=dropout_rate)
    pooled_output = GlobalAveragePooling1D()(transformer_output)
    x = Concatenate()([pooled_output, input_features])

    # Outputs
    price_output = Dense(64, activation='relu')(x)
    price_output = Dense(1, name='price_output')(price_output)

    days_output = Dense(64, activation='relu')(x)
    days_output = Dense(1, name='days_output')(days_output)

    range_output = Dense(64, activation='relu')(x)
    range_output = Dense(y_range.nunique(), activation='softmax', name='range_output')(range_output)

    model = Model(inputs=[input_origen, input_destino, input_salida, input_llegada, input_features],
                  outputs=[price_output, days_output, range_output])

    model.compile(optimizer=Adam(learning_rate=learning_rate),
                  loss={'price_output': 'mse', 'days_output': 'mse', 'range_output': 'sparse_categorical_crossentropy'},
                  metrics={'price_output': 'mae', 'days_output': 'mae', 'range_output': 'accuracy'})
    return model

# Optuna
def objective(trial):
    embedding_dim = trial.suggest_int('embedding_dim', 4, 16)
    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True)
    heads = trial.suggest_int('heads', 1, 4)
    ff_dim = trial.suggest_int('ff_dim', 32, 128)
    dropout_rate = trial.suggest_float('dropout_rate', 0.2, 0.5)

    model = create_model(embedding_dim, learning_rate, heads, ff_dim, dropout_rate)

    model.fit([
        X_train['Origen_int'], X_train['Destino_int'],
        X_train['Hora_Salida_Rango_int'], X_train['Hora_Llegada_Rango_int'],
        X_train[['Duracion_minutos', 'Directo_binario']].values
    ], [y_price_train, y_days_train, y_range_train], epochs=100, batch_size=32, verbose=0)

    y_pred_price, y_pred_days, _ = model.predict([
        X_val['Origen_int'], X_val['Destino_int'],
        X_val['Hora_Salida_Rango_int'], X_val['Hora_Llegada_Rango_int'],
        X_val[['Duracion_minutos', 'Directo_binario']].values
    ])

    return mean_absolute_error(y_price_val, y_pred_price) + mean_absolute_error(y_days_val, y_pred_days)

study = optuna.create_study(direction='minimize')
study.optimize(objective, n_trials=10)

# Entrenamiento final con mejores par谩metros
best = study.best_params
model = create_model(
    best['embedding_dim'],
    best['learning_rate'],
    best['heads'],
    best['ff_dim'],
    best['dropout_rate']
)
start_train = time.time()
model.fit([
    X_train['Origen_int'], X_train['Destino_int'],
    X_train['Hora_Salida_Rango_int'], X_train['Hora_Llegada_Rango_int'],
    X_train[['Duracion_minutos', 'Directo_binario']].values
], [y_price_train, y_days_train, y_range_train], epochs=100, batch_size=32, verbose=0)
end_train = time.time()
# Evaluaci贸n
y_price_pred, y_days_pred, y_range_pred = model.predict([
    X_val['Origen_int'], X_val['Destino_int'],
    X_val['Hora_Salida_Rango_int'], X_val['Hora_Llegada_Rango_int'],
    X_val[['Duracion_minutos', 'Directo_binario']].values
])

# M茅tricas
results_multi_transformer_E = pd.DataFrame([{
    'Modelo': 'Transformer',
    'MAE_Tarifa': mean_absolute_error(y_price_val, y_price_pred),
    'MSE_Tarifa': mean_squared_error(y_price_val, y_price_pred),
    'RMSE_Tarifa': np.sqrt(mean_squared_error(y_price_val, y_price_pred)),
    'R2_Tarifa': r2_score(y_price_val, y_price_pred),

    'MAE_DiasAnt': mean_absolute_error(y_days_val, y_days_pred),
    'MSE_DiasAnt': mean_squared_error(y_days_val, y_days_pred),
    'RMSE_DiasAnt': np.sqrt(mean_squared_error(y_days_val, y_days_pred)),
    'R2_DiasAnt': r2_score(y_days_val, y_days_pred),

    'Accuracy_Rango': accuracy_score(y_range_val, np.argmax(y_range_pred, axis=1)),
    'Precision_Rango': precision_score(y_range_val, np.argmax(y_range_pred, axis=1), average='weighted'),
    'Recall_Rango': recall_score(y_range_val, np.argmax(y_range_pred, axis=1), average='weighted'),
    'F1_Rango': f1_score(y_range_val, np.argmax(y_range_pred, axis=1), average='weighted'),

    'Training_time': end_train - start_train,
    'Best_Params': str(best)
}])

print(results_multi_transformer_E)

"""## **XGBOOST**"""

import pandas as pd
import numpy as np
import optuna
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import (
    mean_squared_error, mean_absolute_error, r2_score,
    accuracy_score, precision_score, recall_score, f1_score
)

# Cargar los embeddings si ya est谩n almacenados en un CSV
df_embed = pd.read_csv("df_embeddings.csv")

# Definir columnas target
target_tarifa = 'Tarifa'
target_dias = 'Dias_hasta_vuelo'
target_rango = 'Rango_Horario_Consulta_int'

# Separar X e y
X = df_embed.drop([target_tarifa, target_dias, target_rango], axis=1)
y_price = df_embed[target_tarifa]
y_days = df_embed[target_dias]
y_range = df_embed[target_rango]

# Dividir en entrenamiento y validaci贸n
X_train, X_val, y_price_train, y_price_val, y_days_train, y_days_val, y_range_train, y_range_val = train_test_split(
    X, y_price, y_days, y_range, test_size=0.2, random_state=42
)

# Funci贸n de objetivo para regresi贸n
def objective_regression(trial, y_train, y_val):
    params = {
        'objective': 'reg:squarederror',
        'eval_metric': 'rmse',
        'learning_rate': trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True),
        'max_depth': trial.suggest_int('max_depth', 2, 8),
        'n_estimators': trial.suggest_int('n_estimators', 20, 100),
    }
    model = xgb.XGBRegressor(**params)
    model.fit(X_train, y_train)
    preds = model.predict(X_val)
    return mean_squared_error(y_val, preds)

# Funci贸n de objetivo para clasificaci贸n
def objective_classification(trial):
    params = {
        'objective': 'multi:softprob',
        'eval_metric': 'mlogloss',
        'num_class': len(np.unique(y_range)),
        'learning_rate': trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True),
        'max_depth': trial.suggest_int('max_depth', 2, 8),
        'n_estimators': trial.suggest_int('n_estimators', 20, 100),
    }
    model = xgb.XGBClassifier(**params)
    model.fit(X_train, y_range_train)
    preds = model.predict(X_val)
    return 1.0 - accuracy_score(y_range_val, preds)

# Optuna: 3 iteraciones para cada tarea
study_price = optuna.create_study(direction='minimize')
study_price.optimize(lambda trial: objective_regression(trial, y_price_train, y_price_val), n_trials=10)

study_days = optuna.create_study(direction='minimize')
study_days.optimize(lambda trial: objective_regression(trial, y_days_train, y_days_val), n_trials=10)

study_range = optuna.create_study(direction='minimize')
study_range.optimize(objective_classification, n_trials=10)

start_training_time = time.time()
# Entrenar modelos finales con los mejores par谩metros
model_price = xgb.train(
    study_price.best_params,
    xgb.DMatrix(X_train, label=y_price_train),
    num_boost_round=50
)

model_days = xgb.train(
    study_days.best_params,
    xgb.DMatrix(X_train, label=y_days_train),
    num_boost_round=50
)

clf_range = xgb.XGBClassifier(**study_range.best_params)
clf_range.fit(X_train, y_range_train)
training_time = time.time() - start_training_time
# Predicciones
price_preds = model_price.predict(xgb.DMatrix(X_val))
days_preds = model_days.predict(xgb.DMatrix(X_val))
range_preds = clf_range.predict(X_val)

# M茅tricas de evaluaci贸n
results_multi_xgboost_E = pd.DataFrame([{
    'Modelo': 'XGBoost',

    'MAE_Tarifa': mean_absolute_error(y_price_val, price_preds),
    'MSE_Tarifa': mean_squared_error(y_price_val, price_preds),
    'RMSE_Tarifa': np.sqrt(mean_squared_error(y_price_val, price_preds)),
    'R2_Tarifa': r2_score(y_price_val, price_preds),

    'MAE_DiasAnt': mean_absolute_error(y_days_val, days_preds),
    'MSE_DiasAnt': mean_squared_error(y_days_val, days_preds),
    'RMSE_DiasAnt': np.sqrt(mean_squared_error(y_days_val, days_preds)),
    'R2_DiasAnt': r2_score(y_days_val, days_preds),

    'Accuracy_Rango': accuracy_score(y_range_val, range_preds),
    'Precision_Rango': precision_score(y_range_val, range_preds, average='weighted', zero_division=0),
    'Recall_Rango': recall_score(y_range_val, range_preds, average='weighted', zero_division=0),
    'F1_Rango': f1_score(y_range_val, range_preds, average='weighted', zero_division=0),

    'Training_time': training_time,
    'Best_Params': str({
        'Tarifa': study_price.best_params,
        'DiasAnt': study_days.best_params,
        'Rango': study_range.best_params
    })
}])

print(results_multi_xgboost_E)

"""## **KNN**"""

import time
import pandas as pd
import numpy as np
from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, accuracy_score, precision_score, recall_score, f1_score
import optuna

# Aseg煤rate de haber cargado el dataset de embeddings generado previamente
df_embed = pd.read_csv("df_embeddings.csv")  # o reemplaza por tu DataFrame existente

# Variables de entrada (solo embeddings)
embed_cols = [col for col in df_embed.columns if col.startswith("embed_feat")]
X = df_embed[embed_cols]

# Variables objetivo
y_price = df_embed['Tarifa']
y_days = df_embed['Dias_hasta_vuelo']
y_range = df_embed['Rango_Horario_Consulta_int']

# Divisi贸n del dataset
X_train, X_val, y_price_train, y_price_val, y_days_train, y_days_val, y_range_train, y_range_val = train_test_split(
    X, y_price, y_days, y_range, test_size=0.2, random_state=42
)

# ------------------------
# OPTUNA
# ------------------------

def objective_knn_reg(trial, y_train, y_val):
    params = {
        'n_neighbors': trial.suggest_int('n_neighbors', 3, 15),
        'weights': trial.suggest_categorical('weights', ['uniform', 'distance']),
        'p': trial.suggest_int('p', 1, 2)
    }
    model = KNeighborsRegressor(**params)
    model.fit(X_train, y_train)
    y_pred = model.predict(X_val)
    return mean_absolute_error(y_val, y_pred)

def objective_knn_cls(trial):
    params = {
        'n_neighbors': trial.suggest_int('n_neighbors', 3, 15),
        'weights': trial.suggest_categorical('weights', ['uniform', 'distance']),
        'p': trial.suggest_int('p', 1, 2)
    }
    model = KNeighborsClassifier(**params)
    model.fit(X_train, y_range_train)
    y_pred = model.predict(X_val)
    return 1 - accuracy_score(y_range_val, y_pred)

study_price = optuna.create_study(direction='minimize')
study_price.optimize(lambda trial: objective_knn_reg(trial, y_price_train, y_price_val), n_trials=10)

study_days = optuna.create_study(direction='minimize')
study_days.optimize(lambda trial: objective_knn_reg(trial, y_days_train, y_days_val), n_trials=10)

study_range = optuna.create_study(direction='minimize')
study_range.optimize(objective_knn_cls, n_trials=10)


# ------------------------
# ENTRENAMIENTO FINAL
# ------------------------

start_optuna = time.time()
model_price = KNeighborsRegressor(**study_price.best_params)
model_price.fit(X_train, y_price_train)
y_price_pred = model_price.predict(X_val)

model_days = KNeighborsRegressor(**study_days.best_params)
model_days.fit(X_train, y_days_train)
y_days_pred = model_days.predict(X_val)

model_range = KNeighborsClassifier(**study_range.best_params)
model_range.fit(X_train, y_range_train)
y_range_pred_classes = model_range.predict(X_val)
end_optuna = time.time()
# ------------------------
# EVALUACIN Y RESULTADOS
# ------------------------

results_multi_knn_E = pd.DataFrame([{
    'Modelo': 'KNN',

    'MAE_Tarifa': mean_absolute_error(y_price_val, y_price_pred),
    'MSE_Tarifa': mean_squared_error(y_price_val, y_price_pred),
    'RMSE_Tarifa': np.sqrt(mean_squared_error(y_price_val, y_price_pred)),
    'R2_Tarifa': r2_score(y_price_val, y_price_pred),

    'MAE_DiasAnt': mean_absolute_error(y_days_val, y_days_pred),
    'MSE_DiasAnt': mean_squared_error(y_days_val, y_days_pred),
    'RMSE_DiasAnt': np.sqrt(mean_squared_error(y_days_val, y_days_pred)),
    'R2_DiasAnt': r2_score(y_days_val, y_days_pred),

    'Accuracy_Rango': accuracy_score(y_range_val, y_range_pred_classes),
    'Precision_Rango': precision_score(y_range_val, y_range_pred_classes, average='weighted'),
    'Recall_Rango': recall_score(y_range_val, y_range_pred_classes, average='weighted'),
    'F1_Rango': f1_score(y_range_val, y_range_pred_classes, average='weighted'),

    'Training_time': time.time() - end_optuna,
}])

# Mostrar mejores hiperpar谩metros por cada tarea
results_multi_knn_E['Best_Params'] = [str({
    'Tarifa': study_price.best_params,
    'Dias': study_days.best_params,
    'Rango': study_range.best_params
})]

print(results_multi_knn_E)

"""## **ARBOL DE DESICION**"""

import time
import pandas as pd
import numpy as np
from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import (
    mean_absolute_error, mean_squared_error, r2_score,
    accuracy_score, precision_score, recall_score, f1_score
)
import optuna

# Aseg煤rate de tener cargado tu DataFrame con embeddings y targets:
df_embed = pd.read_csv("df_embeddings.csv")

X = df_embed[[col for col in df_embed.columns if col.startswith("embed_feat_")]]
y_price = df_embed["Tarifa"]
y_days = df_embed["Dias_hasta_vuelo"]
y_range = df_embed["Rango_Horario_Consulta_int"]

X_train, X_val, y_price_train, y_price_val, y_days_train, y_days_val, y_range_train, y_range_val = train_test_split(
    X, y_price, y_days, y_range, test_size=0.2, random_state=42
)

# ---------------------- OPTIMIZACIN CON OPTUNA ---------------------- #
start_optuna = time.time()

# Funci贸n para regresi贸n
def objective_dt_reg(trial, y_train, y_val):
    params = {
        "max_depth": trial.suggest_int("max_depth", 50, 100),
        "min_samples_split": trial.suggest_int("min_samples_split", 2, 10)
    }
    model = DecisionTreeRegressor(**params)
    model.fit(X_train, y_train)
    preds = model.predict(X_val)
    return mean_absolute_error(y_val, preds)

# Funci贸n para clasificaci贸n
def objective_dt_cls(trial):
    params = {
        "max_depth": trial.suggest_int("max_depth", 50, 100),
        "min_samples_split": trial.suggest_int("min_samples_split", 2, 10)
    }
    model = DecisionTreeClassifier(**params)
    model.fit(X_train, y_range_train)
    preds = model.predict(X_val)
    return 1 - accuracy_score(y_range_val, preds)

# Optuna por tarea
study_dt_price = optuna.create_study(direction="minimize")
study_dt_price.optimize(lambda trial: objective_dt_reg(trial, y_price_train, y_price_val), n_trials=10)

study_dt_days = optuna.create_study(direction="minimize")
study_dt_days.optimize(lambda trial: objective_dt_reg(trial, y_days_train, y_days_val), n_trials=10)

study_dt_range = optuna.create_study(direction="minimize")
study_dt_range.optimize(objective_dt_cls, n_trials=10)

end_optuna = time.time()

# ---------------------- ENTRENAMIENTO FINAL ---------------------- #
model_dt_price = DecisionTreeRegressor(**study_dt_price.best_params)
model_dt_price.fit(X_train, y_price_train)
y_pred_dt_price = model_dt_price.predict(X_val)

model_dt_days = DecisionTreeRegressor(**study_dt_days.best_params)
model_dt_days.fit(X_train, y_days_train)
y_pred_dt_days = model_dt_days.predict(X_val)

model_dt_range = DecisionTreeClassifier(**study_dt_range.best_params)
model_dt_range.fit(X_train, y_range_train)
y_pred_dt_range = model_dt_range.predict(X_val)

# ---------------------- MTRICAS ---------------------- #
results_multi_dt_E = pd.DataFrame([{
    "Modelo": "Decision Tree Multioutput (Embeddings)",

    "MAE_Tarifa": mean_absolute_error(y_price_val, y_pred_dt_price),
    "MSE_Tarifa": mean_squared_error(y_price_val, y_pred_dt_price),
    "RMSE_Tarifa": np.sqrt(mean_squared_error(y_price_val, y_pred_dt_price)),
    "R2_Tarifa": r2_score(y_price_val, y_pred_dt_price),

    "MAE_DiasAnt": mean_absolute_error(y_days_val, y_pred_dt_days),
    "MSE_DiasAnt": mean_squared_error(y_days_val, y_pred_dt_days),
    "RMSE_DiasAnt": np.sqrt(mean_squared_error(y_days_val, y_pred_dt_days)),
    "R2_DiasAnt": r2_score(y_days_val, y_pred_dt_days),

    "Accuracy_Rango": accuracy_score(y_range_val, y_pred_dt_range),
    "Precision_Rango": precision_score(y_range_val, y_pred_dt_range, average="weighted"),
    "Recall_Rango": recall_score(y_range_val, y_pred_dt_range, average="weighted"),
    "F1_Rango": f1_score(y_range_val, y_pred_dt_range, average="weighted"),

    "Training_time": time.time() - end_optuna,

}])

results_multi_dt_E["Best_Params"] = [str({
    "Tarifa": study_dt_price.best_params,
    "Dias_hasta_vuelo": study_dt_days.best_params,
    "Rango_Horario_Consulta_int": study_dt_range.best_params
})]

print(results_multi_dt_E)

"""## **RANDOM FOREST**"""

import time
import optuna
import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, accuracy_score, precision_score, recall_score, f1_score
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# -------------------- CARGA DEL DATASET CON EMBEDDINGS --------------------
df_embed = pd.read_csv('df_embeddings.csv')  # Ajusta la ruta

# Separaci贸n de variables
X = df_embed.drop(columns=['Tarifa', 'Dias_hasta_vuelo', 'Rango_Horario_Consulta_int'])
y_price = df_embed['Tarifa']
y_days = df_embed['Dias_hasta_vuelo']
y_range = df_embed['Rango_Horario_Consulta_int']

# Divisi贸n
X_train, X_val, y_price_train, y_price_val, y_days_train, y_days_val, y_range_train, y_range_val = train_test_split(
    X, y_price, y_days, y_range, test_size=0.2, random_state=42
)

# -------------------- OPTUNA --------------------
start_optuna = time.time()

def objective_rf_reg(trial, y_train, y_val):
    params = {
        'n_estimators': trial.suggest_int('n_estimators', 50, 300, step=50),
        'max_depth': trial.suggest_int('max_depth', 3, 20),
        'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),
        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 5)
    }
    model = RandomForestRegressor(**params, random_state=42)
    model.fit(X_train, y_train)
    preds = model.predict(X_val)
    return mean_absolute_error(y_val, preds)

def objective_rf_cls(trial):
    params = {
        'n_estimators': trial.suggest_int('n_estimators', 50, 300, step=50),
        'max_depth': trial.suggest_int('max_depth', 3, 20),
        'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),
        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 5)
    }
    model = RandomForestClassifier(**params, random_state=42)
    model.fit(X_train, y_range_train)
    preds = model.predict(X_val)
    return 1 - accuracy_score(y_range_val, preds)

# Estudios
study_rf_price = optuna.create_study(direction='minimize')
study_rf_price.optimize(lambda trial: objective_rf_reg(trial, y_price_train, y_price_val), n_trials=10)

study_rf_days = optuna.create_study(direction='minimize')
study_rf_days.optimize(lambda trial: objective_rf_reg(trial, y_days_train, y_days_val), n_trials=10)

study_rf_range = optuna.create_study(direction='minimize')
study_rf_range.optimize(objective_rf_cls, n_trials=10)

end_optuna = time.time()

# -------------------- ENTRENAMIENTO FINAL --------------------
model_rf_price = RandomForestRegressor(**study_rf_price.best_params, random_state=42)
model_rf_price.fit(X_train, y_price_train)
y_pred_rf_price = model_rf_price.predict(X_val)

model_rf_days = RandomForestRegressor(**study_rf_days.best_params, random_state=42)
model_rf_days.fit(X_train, y_days_train)
y_pred_rf_days = model_rf_days.predict(X_val)

model_rf_range = RandomForestClassifier(**study_rf_range.best_params, random_state=42)
model_rf_range.fit(X_train, y_range_train)
y_pred_rf_range = model_rf_range.predict(X_val)

# -------------------- MTRICAS --------------------
results_multi_rf_E = pd.DataFrame([{
    'Modelo': 'Random Forest',

    'MAE_Tarifa': mean_absolute_error(y_price_val, y_pred_rf_price),
    'MSE_Tarifa': mean_squared_error(y_price_val, y_pred_rf_price),
    'RMSE_Tarifa': np.sqrt(mean_squared_error(y_price_val, y_pred_rf_price)),
    'R2_Tarifa': r2_score(y_price_val, y_pred_rf_price),

    'MAE_DiasAnt': mean_absolute_error(y_days_val, y_pred_rf_days),
    'MSE_DiasAnt': mean_squared_error(y_days_val, y_pred_rf_days),
    'RMSE_DiasAnt': np.sqrt(mean_squared_error(y_days_val, y_pred_rf_days)),
    'R2_DiasAnt': r2_score(y_days_val, y_pred_rf_days),

    'Accuracy_Rango': accuracy_score(y_range_val, y_pred_rf_range),
    'Precision_Rango': precision_score(y_range_val, y_pred_rf_range, average='weighted'),
    'Recall_Rango': recall_score(y_range_val, y_pred_rf_range, average='weighted'),
    'F1_Rango': f1_score(y_range_val, y_pred_rf_range, average='weighted'),

    'Training_time': time.time() - end_optuna,
    'Best_Params': str({
        'Tarifa': study_rf_price.best_params,
        'DiasAnt': study_rf_days.best_params,
        'Rango': study_rf_range.best_params
    })
}])

print(results_multi_rf_E)

"""## **ALMACENAR RESULTADOS**"""

import pandas as pd

# --- Consolidar todos los resultados en una lista
results_multi_E = [
    results_multi_lstm_E ,
    results_multi_gru_E,
    pd.DataFrame([results_multi_tcn_E]), # Convert the dictionary to a DataFrame
    results_multi_transformer_E,
    results_multi_xgboost_E,
    results_multi_knn_E,
    results_multi_dt_E,
    results_multi_rf_E
]

# --- Crear DataFrame by concatenating the list of DataFrames
df_results_multi_E = pd.concat(results_multi_E, ignore_index=True)


# --- Guardar a CSV
df_results_multi_E.to_csv("resultados_modelos_multioutput.csv", index=False)

# --- Mostrar resultados como tabla
from IPython.display import display
display(df_results_multi_E)