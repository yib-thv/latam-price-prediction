# -*- coding: utf-8 -*-
"""1_multi_E_v3

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yviyDRGC2vSxMMbQ404F0-ZEwSjiUeDG

# **PROJECT: PREDICTION OF AIR TICKET PRICES FOR DOMESTIC FLIGHTS IN PERU ON LATAM AIRLINE**

------

# **ENTRENAMIENTO 1: OBJETIVO PREDECIR TARIFA**
"""

from IPython.display import display

# Importar las librerías necesarias
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Cargar el dataset
df = pd.read_csv('flights_data_final.csv')

# Mostrar las primeras filas
print("Primeras 5 filas del dataset:")
display(df.head())

"""## **MODELO 1: LSTM - Long Short-Term Memory**"""

import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Embedding, LSTM, Dense, Input, Concatenate, Reshape
from tensorflow.keras.optimizers import Adam
from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import TimeSeriesSplit
import optuna
import time

# Normalización y preparación de datos
X = df[['Origen_int', 'Destino_int', 'Duracion_minutos', 'Directo_binario',
        'Dias_hasta_vuelo', 'Rango_Horario_Consulta_int', 'Hora_Salida_Rango_int', 'Hora_Llegada_Rango_int']]
y = df['Tarifa']

scaler = StandardScaler()
X.loc[:, ['Duracion_minutos', 'Dias_hasta_vuelo']] = scaler.fit_transform(X[['Duracion_minutos', 'Dias_hasta_vuelo']])


def objective(trial):
    #  Hiperparámetros a optimizar
    embedding_dim = trial.suggest_categorical('embedding_dim', [4, 8, 16])
    lstm_units = trial.suggest_categorical('lstm_units', [16, 32, 64])
    dense_units = trial.suggest_categorical('dense_units', [16, 32])
    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)
    learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-2, log=True)

    #  División en entrenamiento/validación
    split_index = int(len(X) * 0.8)
    X_train, X_val = X.iloc[:split_index], X.iloc[split_index:]
    y_train, y_val = y.iloc[:split_index], y.iloc[split_index:]

    #  Definición del modelo
    input_origen = Input(shape=(1,))
    input_destino = Input(shape=(1,))
    input_rango_horario = Input(shape=(1,))
    input_salida = Input(shape=(1,))
    input_llegada = Input(shape=(1,))
    features = Input(shape=(3,))

    embedding_origen = Embedding(X['Origen_int'].nunique(), embedding_dim)(input_origen)
    embedding_destino = Embedding(X['Destino_int'].nunique(), embedding_dim)(input_destino)
    embedding_rango_horario = Embedding(X['Rango_Horario_Consulta_int'].nunique(), embedding_dim)(input_rango_horario)
    embedding_salida = Embedding(X['Hora_Salida_Rango_int'].nunique(), embedding_dim)(input_salida)
    embedding_llegada = Embedding(X['Hora_Llegada_Rango_int'].nunique(), embedding_dim)(input_llegada)

    features_reshaped = Reshape((1, 3))(features)
    x = Concatenate()([embedding_origen, embedding_destino, embedding_rango_horario,
                       embedding_salida, embedding_llegada, features_reshaped])
    x = LSTM(lstm_units, return_sequences=False)(x)
    x = Dense(dense_units, activation='relu')(x)
    output = Dense(1)(x)

    model = Model(inputs=[input_origen, input_destino, input_rango_horario,
                          input_salida, input_llegada, features], outputs=output)
    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mse')

    #  Entrenamiento (1 epoch para prueba)
    model.fit([X_train['Origen_int'], X_train['Destino_int'], X_train['Rango_Horario_Consulta_int'],
               X_train['Hora_Salida_Rango_int'], X_train['Hora_Llegada_Rango_int'],
               X_train[['Duracion_minutos', 'Directo_binario', 'Dias_hasta_vuelo']].values],
              y_train, epochs=100, batch_size=32, verbose=0)

    #  Evaluación
    y_pred = model.predict([X_val['Origen_int'], X_val['Destino_int'], X_val['Rango_Horario_Consulta_int'],
                            X_val['Hora_Salida_Rango_int'], X_val['Hora_Llegada_Rango_int'],
                            X_val[['Duracion_minutos', 'Directo_binario', 'Dias_hasta_vuelo']].values])

    return mean_absolute_error(y_val, y_pred)

#  Ejecutar Optuna (1 trial para prueba)
study = optuna.create_study(direction='minimize')
study.optimize(objective, n_trials=10)

#  Entrenamiento final con mejores parámetros
best_params = study.best_params
embedding_dim = best_params['embedding_dim']
lstm_units = best_params['lstm_units']
dense_units = best_params['dense_units']
dropout_rate = best_params['dropout_rate']
learning_rate = best_params['learning_rate']

#  División simple
split_index = int(len(X) * 0.8)
X_train, X_val = X.iloc[:split_index], X.iloc[split_index:]
y_train, y_val = y.iloc[:split_index], y.iloc[split_index:]

#  Modelo final
input_origen = Input(shape=(1,))
input_destino = Input(shape=(1,))
input_rango_horario = Input(shape=(1,))
input_salida = Input(shape=(1,))
input_llegada = Input(shape=(1,))
features = Input(shape=(3,))

embedding_origen = Embedding(X['Origen_int'].nunique(), embedding_dim)(input_origen)
embedding_destino = Embedding(X['Destino_int'].nunique(), embedding_dim)(input_destino)
embedding_rango_horario = Embedding(X['Rango_Horario_Consulta_int'].nunique(), embedding_dim)(input_rango_horario)
embedding_salida = Embedding(X['Hora_Salida_Rango_int'].nunique(), embedding_dim)(input_salida)
embedding_llegada = Embedding(X['Hora_Llegada_Rango_int'].nunique(), embedding_dim)(input_llegada)

features_reshaped = Reshape((1, 3))(features)
x = Concatenate()([embedding_origen, embedding_destino, embedding_rango_horario,
                   embedding_salida, embedding_llegada, features_reshaped])
x = LSTM(lstm_units, return_sequences=False)(x)
x = Dense(dense_units, activation='relu')(x)
output = Dense(1)(x)

model = Model(inputs=[input_origen, input_destino, input_rango_horario,
                      input_salida, input_llegada, features], outputs=output)
model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mse')
start_time = time.time()
#  Entrenamiento final (1 epoch para prueba)
model.fit([X_train['Origen_int'], X_train['Destino_int'], X_train['Rango_Horario_Consulta_int'],
           X_train['Hora_Salida_Rango_int'], X_train['Hora_Llegada_Rango_int'],
           X_train[['Duracion_minutos', 'Directo_binario', 'Dias_hasta_vuelo']].values],
          y_train, epochs=100, batch_size=32, verbose=0)
end_time = time.time()  #  Fin del cronómetro
training_time = end_time - start_time  #  Duración total en segundos
#  Predicción final
y_pred = model.predict([X_val['Origen_int'], X_val['Destino_int'], X_val['Rango_Horario_Consulta_int'],
                        X_val['Hora_Salida_Rango_int'], X_val['Hora_Llegada_Rango_int'],
                        X_val[['Duracion_minutos', 'Directo_binario', 'Dias_hasta_vuelo']].values])

#  Métricas
mae = mean_absolute_error(y_val, y_pred)
mse = mean_squared_error(y_val, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_val, y_pred)

#  Resultados
final_metrics_lstm_obj1E = pd.Series({
    'MAE': mae,
    'MSE': mse,
    'RMSE': rmse,
    'R2': r2,
    'Training_Time': training_time,
    'Best_Params': str(best_params)
})

print(" Métricas finales (1 epoch):")
print(final_metrics_lstm_obj1E)

"""## **MODELO 2: GRU - Gated Recurrent Unit**"""

import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Embedding, GRU, Dense, Input, Concatenate, Reshape
from tensorflow.keras.optimizers import Adam
from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error
from sklearn.preprocessing import StandardScaler
import optuna
import time

# Normalización de columnas numéricas
X = df[['Origen_int', 'Destino_int', 'Duracion_minutos', 'Directo_binario',
        'Dias_hasta_vuelo', 'Rango_Horario_Consulta_int', 'Hora_Salida_Rango_int', 'Hora_Llegada_Rango_int']]
y = df['Tarifa']

scaler = StandardScaler()
X.loc[:, ['Duracion_minutos', 'Dias_hasta_vuelo']] = scaler.fit_transform(X[['Duracion_minutos', 'Dias_hasta_vuelo']])

# División simple en entrenamiento y validación
train_size = int(0.8 * len(X))
X_train, X_val = X.iloc[:train_size], X.iloc[train_size:]
y_train, y_val = y.iloc[:train_size], y.iloc[train_size:]

# Función objetivo para Optuna
def objective_gru(trial):
    embedding_dim = trial.suggest_int('embedding_dim', 4, 16)
    gru_units = trial.suggest_int('gru_units', 32, 128)
    dense_units = trial.suggest_int('dense_units', 16, 128)
    learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-2, log=True)

    input_origen = Input(shape=(1,))
    input_destino = Input(shape=(1,))
    input_rango_horario = Input(shape=(1,))
    input_salida = Input(shape=(1,))
    input_llegada = Input(shape=(1,))
    features = Input(shape=(3,))

    embedding_origen = Embedding(input_dim=X['Origen_int'].nunique(), output_dim=embedding_dim)(input_origen)
    embedding_destino = Embedding(input_dim=X['Destino_int'].nunique(), output_dim=embedding_dim)(input_destino)
    embedding_rango_horario = Embedding(input_dim=X['Rango_Horario_Consulta_int'].nunique(), output_dim=embedding_dim)(input_rango_horario)
    embedding_salida = Embedding(input_dim=X['Hora_Salida_Rango_int'].nunique(), output_dim=embedding_dim)(input_salida)
    embedding_llegada = Embedding(input_dim=X['Hora_Llegada_Rango_int'].nunique(), output_dim=embedding_dim)(input_llegada)

    features_reshaped = Reshape((1, 3))(features)
    x = Concatenate()([embedding_origen, embedding_destino, embedding_rango_horario,
                       embedding_salida, embedding_llegada, features_reshaped])

    x = GRU(gru_units, return_sequences=False)(x)
    x = Dense(dense_units, activation='relu')(x)
    x = Dense(1)(x)

    model_gru = Model(inputs=[input_origen, input_destino, input_rango_horario,
                              input_salida, input_llegada, features], outputs=x)
    model_gru.compile(optimizer=Adam(learning_rate=learning_rate), loss='mse')

    model_gru.fit([X_train['Origen_int'], X_train['Destino_int'], X_train['Rango_Horario_Consulta_int'],
                   X_train['Hora_Salida_Rango_int'], X_train['Hora_Llegada_Rango_int'],
                   X_train[['Duracion_minutos', 'Directo_binario', 'Dias_hasta_vuelo']].values],
                  y_train, epochs=100, batch_size=32, verbose=0)

    y_pred = model_gru.predict([X_val['Origen_int'], X_val['Destino_int'], X_val['Rango_Horario_Consulta_int'],
                                X_val['Hora_Salida_Rango_int'], X_val['Hora_Llegada_Rango_int'],
                                X_val[['Duracion_minutos', 'Directo_binario', 'Dias_hasta_vuelo']].values])

    return np.sqrt(mean_squared_error(y_val, y_pred))

# Optuna para GRU con un solo trial
study_gru = optuna.create_study(direction='minimize')
study_gru.optimize(objective_gru, n_trials=10)

print("Best parameters (GRU):", study_gru.best_params)

# Evaluación final con los mejores parámetros
best_params = study_gru.best_params
embedding_dim = best_params['embedding_dim']
gru_units = best_params['gru_units']
dense_units = best_params['dense_units']
learning_rate = best_params['learning_rate']

start_time = time.time()

input_origen = Input(shape=(1,))
input_destino = Input(shape=(1,))
input_rango_horario = Input(shape=(1,))
input_salida = Input(shape=(1,))
input_llegada = Input(shape=(1,))
features = Input(shape=(3,))

embedding_origen = Embedding(input_dim=X['Origen_int'].nunique(), output_dim=embedding_dim)(input_origen)
embedding_destino = Embedding(input_dim=X['Destino_int'].nunique(), output_dim=embedding_dim)(input_destino)
embedding_rango_horario = Embedding(input_dim=X['Rango_Horario_Consulta_int'].nunique(), output_dim=embedding_dim)(input_rango_horario)
embedding_salida = Embedding(input_dim=X['Hora_Salida_Rango_int'].nunique(), output_dim=embedding_dim)(input_salida)
embedding_llegada = Embedding(input_dim=X['Hora_Llegada_Rango_int'].nunique(), output_dim=embedding_dim)(input_llegada)

features_reshaped = Reshape((1, 3))(features)
x = Concatenate()([embedding_origen, embedding_destino, embedding_rango_horario,
                   embedding_salida, embedding_llegada, features_reshaped])

x = GRU(gru_units, return_sequences=False)(x)
x = Dense(dense_units, activation='relu')(x)
x = Dense(1)(x)

model_gru = Model(inputs=[input_origen, input_destino, input_rango_horario,
                          input_salida, input_llegada, features], outputs=x)
model_gru.compile(optimizer=Adam(learning_rate=learning_rate), loss='mse')

model_gru.fit([X_train['Origen_int'], X_train['Destino_int'], X_train['Rango_Horario_Consulta_int'],
               X_train['Hora_Salida_Rango_int'], X_train['Hora_Llegada_Rango_int'],
               X_train[['Duracion_minutos', 'Directo_binario', 'Dias_hasta_vuelo']].values],
              y_train, epochs=100, batch_size=32, verbose=0)

y_pred = model_gru.predict([X_val['Origen_int'], X_val['Destino_int'], X_val['Rango_Horario_Consulta_int'],
                            X_val['Hora_Salida_Rango_int'], X_val['Hora_Llegada_Rango_int'],
                            X_val[['Duracion_minutos', 'Directo_binario', 'Dias_hasta_vuelo']].values])

# Métricas finales
final_metrics = {
    'MAE': mean_absolute_error(y_val, y_pred),
    'MSE': mean_squared_error(y_val, y_pred),
    'RMSE': np.sqrt(mean_squared_error(y_val, y_pred)),
    'R2': r2_score(y_val, y_pred),
    'Training_Time': time.time() - start_time,
    'Best_Params': str(study_gru.best_params)
}

final_gru_metrics_obj1E = pd.Series(final_metrics)
print("Metricas finales GRU:")
print(final_gru_metrics_obj1E)

"""## **MODELO 3: TCN - Temporal Convolutional Networks**

Utilizan convoluciones causales para asegurar que la predicción en un tiempo
t solo dependa de la información de tiempos anteriores.
"""

import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Embedding, Dense, Input, Concatenate, Reshape
from tensorflow.keras.optimizers import Adam
from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error
from sklearn.preprocessing import StandardScaler
from tcn import TCN # Import TCN after successful installation
import optuna
import time

# Preparación de datos
X = df[['Origen_int', 'Destino_int', 'Duracion_minutos', 'Directo_binario',
        'Dias_hasta_vuelo', 'Rango_Horario_Consulta_int', 'Hora_Salida_Rango_int', 'Hora_Llegada_Rango_int']]
y = df['Tarifa']

scaler = StandardScaler()
X.loc[:, ['Duracion_minutos', 'Dias_hasta_vuelo']] = scaler.fit_transform(X[['Duracion_minutos', 'Dias_hasta_vuelo']])

# Definición del objetivo de Optuna sin TimeSeriesSplit

def objective_tcn(trial):
    embedding_dim = trial.suggest_int('embedding_dim', 4, 16)
    tcn_filters = trial.suggest_int('tcn_filters', 32, 128)
    dense_units = trial.suggest_int('dense_units', 16, 128)
    learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-2, log=True)

    # División simple de datos
    train_size = int(0.8 * len(X))
    X_train, X_val = X.iloc[:train_size], X.iloc[train_size:]
    y_train, y_val = y.iloc[:train_size], y.iloc[train_size:]

    input_origen = Input(shape=(1,))
    input_destino = Input(shape=(1,))
    input_rango_horario = Input(shape=(1,))
    input_salida = Input(shape=(1,))
    input_llegada = Input(shape=(1,))
    features = Input(shape=(3,))

    embedding_origen = Embedding(input_dim=X['Origen_int'].nunique(), output_dim=embedding_dim)(input_origen)
    embedding_destino = Embedding(input_dim=X['Destino_int'].nunique(), output_dim=embedding_dim)(input_destino)
    embedding_rango_horario = Embedding(input_dim=X['Rango_Horario_Consulta_int'].nunique(), output_dim=embedding_dim)(input_rango_horario)
    embedding_salida = Embedding(input_dim=X['Hora_Salida_Rango_int'].nunique(), output_dim=embedding_dim)(input_salida)
    embedding_llegada = Embedding(input_dim=X['Hora_Llegada_Rango_int'].nunique(), output_dim=embedding_dim)(input_llegada)

    features_reshaped = Reshape((1, 3))(features)
    x = Concatenate()([embedding_origen, embedding_destino, embedding_rango_horario,
                       embedding_salida, embedding_llegada, features_reshaped])

    x = TCN(nb_filters=tcn_filters, return_sequences=False)(x)
    x = Dense(dense_units, activation='relu')(x)
    x = Dense(1)(x)

    model_tcn = Model(inputs=[input_origen, input_destino, input_rango_horario,
                              input_salida, input_llegada, features], outputs=x)
    model_tcn.compile(optimizer=Adam(learning_rate=learning_rate), loss='mse')

    model_tcn.fit([X_train['Origen_int'], X_train['Destino_int'], X_train['Rango_Horario_Consulta_int'],
                   X_train['Hora_Salida_Rango_int'], X_train['Hora_Llegada_Rango_int'],
                   X_train[['Duracion_minutos', 'Directo_binario', 'Dias_hasta_vuelo']].values],
                  y_train, epochs=100, batch_size=32, verbose=0)

    y_pred = model_tcn.predict([X_val['Origen_int'], X_val['Destino_int'], X_val['Rango_Horario_Consulta_int'],
                                X_val['Hora_Salida_Rango_int'], X_val['Hora_Llegada_Rango_int'],
                                X_val[['Duracion_minutos', 'Directo_binario', 'Dias_hasta_vuelo']].values])

    rmse_tcn = np.sqrt(mean_squared_error(y_val, y_pred))
    return rmse_tcn

# Optimización con un solo trial
study_tcn = optuna.create_study(direction='minimize')
study_tcn.optimize(objective_tcn, n_trials=10)

print("Best parameters TCN:", study_tcn.best_params)

# Entrenamiento final con mejores hiperparámetros
start_time = time.time()
best_params = study_tcn.best_params
embedding_dim = best_params['embedding_dim']
tcn_filters = best_params['tcn_filters']
dense_units = best_params['dense_units']
learning_rate = best_params['learning_rate']

train_size = int(0.8 * len(X))
X_train, X_val = X.iloc[:train_size], X.iloc[train_size:]
y_train, y_val = y.iloc[:train_size], y.iloc[train_size:]

input_origen = Input(shape=(1,))
input_destino = Input(shape=(1,))
input_rango_horario = Input(shape=(1,))
input_salida = Input(shape=(1,))
input_llegada = Input(shape=(1,))
features = Input(shape=(3,))

embedding_origen = Embedding(input_dim=X['Origen_int'].nunique(), output_dim=embedding_dim)(input_origen)
embedding_destino = Embedding(input_dim=X['Destino_int'].nunique(), output_dim=embedding_dim)(input_destino)
embedding_rango_horario = Embedding(input_dim=X['Rango_Horario_Consulta_int'].nunique(), output_dim=embedding_dim)(input_rango_horario)
embedding_salida = Embedding(input_dim=X['Hora_Salida_Rango_int'].nunique(), output_dim=embedding_dim)(input_salida)
embedding_llegada = Embedding(input_dim=X['Hora_Llegada_Rango_int'].nunique(), output_dim=embedding_dim)(input_llegada)

features_reshaped = Reshape((1, 3))(features)
x = Concatenate()([embedding_origen, embedding_destino, embedding_rango_horario,
                   embedding_salida, embedding_llegada, features_reshaped])

x = TCN(nb_filters=tcn_filters, return_sequences=False)(x)
x = Dense(dense_units, activation='relu')(x)
x = Dense(1)(x)

model_tcn = Model(inputs=[input_origen, input_destino, input_rango_horario,
                          input_salida, input_llegada, features], outputs=x)
model_tcn.compile(optimizer=Adam(learning_rate=learning_rate), loss='mse')

model_tcn.fit([X_train['Origen_int'], X_train['Destino_int'], X_train['Rango_Horario_Consulta_int'],
               X_train['Hora_Salida_Rango_int'], X_train['Hora_Llegada_Rango_int'],
               X_train[['Duracion_minutos', 'Directo_binario', 'Dias_hasta_vuelo']].values],
              y_train, epochs=100, batch_size=32, verbose=0)

y_pred = model_tcn.predict([X_val['Origen_int'], X_val['Destino_int'], X_val['Rango_Horario_Consulta_int'],
                            X_val['Hora_Salida_Rango_int'], X_val['Hora_Llegada_Rango_int'],
                            X_val[['Duracion_minutos', 'Directo_binario', 'Dias_hasta_vuelo']].values])

final_metrics_tcn_obj1E = {
    'MAE': mean_absolute_error(y_val, y_pred),
    'MSE': mean_squared_error(y_val, y_pred),
    'RMSE': np.sqrt(mean_squared_error(y_val, y_pred)),
    'R2': r2_score(y_val, y_pred),
    'Training_Time': time.time() - start_time,
    'Best_Params': str(best_params)
}

print("\nPromedios finales de las métricas TCN:")
print(pd.Series(final_metrics_tcn_obj1E))

"""## **MODELO 4: TRANSFORMERS**

Mecanismo de Atención:

Utilizan un mecanismo de atención que permite a la red enfocarse en diferentes partes de la entrada de manera dinámica.
"""

import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Embedding, Dense, Flatten, Input, Concatenate, Dropout, Reshape
from tensorflow.keras.optimizers import Adam
from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error
from sklearn.preprocessing import StandardScaler
import optuna
import time

# Normalización y preparación de datos
X = df[['Origen_int', 'Destino_int', 'Duracion_minutos', 'Directo_binario',
        'Dias_hasta_vuelo', 'Rango_Horario_Consulta_int', 'Hora_Salida_Rango_int', 'Hora_Llegada_Rango_int']]
y = df['Tarifa']

scaler = StandardScaler()
X[['Duracion_minutos', 'Dias_hasta_vuelo']] = X[['Duracion_minutos', 'Dias_hasta_vuelo']].astype(float)
X[['Duracion_minutos', 'Dias_hasta_vuelo']] = scaler.fit_transform(X[['Duracion_minutos', 'Dias_hasta_vuelo']])

# Dividir una vez (80/20) para entrenamiento y validación
split_index = int(len(X) * 0.8)
X_train, X_val = X.iloc[:split_index], X.iloc[split_index:]
y_train, y_val = y.iloc[:split_index], y.iloc[split_index:]

# Optuna
def objective(trial):
    embedding_dim = trial.suggest_categorical("embedding_dim", [4, 8, 16])
    num_heads = trial.suggest_int('num_heads', 2, 8)
    ff_dim = trial.suggest_int('ff_dim', 32, 128)
    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)
    learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-2, log=True)

    input_origen = Input(shape=(1,))
    input_destino = Input(shape=(1,))
    input_rango_horario = Input(shape=(1,))
    input_salida = Input(shape=(1,))
    input_llegada = Input(shape=(1,))
    features = Input(shape=(3,))

    embedding_origen = Embedding(input_dim=X['Origen_int'].nunique(), output_dim=embedding_dim)(input_origen)
    embedding_destino = Embedding(input_dim=X['Destino_int'].nunique(), output_dim=embedding_dim)(input_destino)
    embedding_rango_horario = Embedding(input_dim=X['Rango_Horario_Consulta_int'].nunique(), output_dim=embedding_dim)(input_rango_horario)
    embedding_salida = Embedding(input_dim=X['Hora_Salida_Rango_int'].nunique(), output_dim=embedding_dim)(input_salida)
    embedding_llegada = Embedding(input_dim=X['Hora_Llegada_Rango_int'].nunique(), output_dim=embedding_dim)(input_llegada)

    features_reshaped = Reshape((1, 3))(features)

    x = Concatenate(axis=2)([embedding_origen, embedding_destino, embedding_rango_horario,
                             embedding_salida, embedding_llegada, features_reshaped])
    x = Flatten()(x)
    ffn = Dense(ff_dim, activation='relu')(x)
    ffn = Dropout(dropout_rate)(ffn)
    ffn = Dense(1)(ffn)

    model = Model(inputs=[input_origen, input_destino, input_rango_horario,
                          input_salida, input_llegada, features], outputs=ffn)
    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mse')

    model.fit([X_train['Origen_int'], X_train['Destino_int'], X_train['Rango_Horario_Consulta_int'],
               X_train['Hora_Salida_Rango_int'], X_train['Hora_Llegada_Rango_int'],
               X_train[['Duracion_minutos', 'Directo_binario', 'Dias_hasta_vuelo']].values],
              y_train, epochs=100, batch_size=32, verbose=0)

    y_pred = model.predict([X_val['Origen_int'], X_val['Destino_int'], X_val['Rango_Horario_Consulta_int'],
                            X_val['Hora_Salida_Rango_int'], X_val['Hora_Llegada_Rango_int'],
                            X_val[['Duracion_minutos', 'Directo_binario', 'Dias_hasta_vuelo']].values])

    return np.sqrt(mean_squared_error(y_val, y_pred))

# Optuna run con 1 trial
study = optuna.create_study(direction='minimize')
study.optimize(objective, n_trials=10)

# Evaluación final con mejores hiperparámetros
best_params = study.best_params
embedding_dim = best_params['embedding_dim']
ff_dim = best_params['ff_dim']
dropout_rate = best_params['dropout_rate']
learning_rate = best_params['learning_rate']

start_time = time.time()

input_origen = Input(shape=(1,))
input_destino = Input(shape=(1,))
input_rango_horario = Input(shape=(1,))
input_salida = Input(shape=(1,))
input_llegada = Input(shape=(1,))
features = Input(shape=(3,))

embedding_origen = Embedding(input_dim=X['Origen_int'].nunique(), output_dim=embedding_dim)(input_origen)
embedding_destino = Embedding(input_dim=X['Destino_int'].nunique(), output_dim=embedding_dim)(input_destino)
embedding_rango_horario = Embedding(input_dim=X['Rango_Horario_Consulta_int'].nunique(), output_dim=embedding_dim)(input_rango_horario)
embedding_salida = Embedding(input_dim=X['Hora_Salida_Rango_int'].nunique(), output_dim=embedding_dim)(input_salida)
embedding_llegada = Embedding(input_dim=X['Hora_Llegada_Rango_int'].nunique(), output_dim=embedding_dim)(input_llegada)

features_reshaped = Reshape((1, 3))(features)

x = Concatenate(axis=2)([embedding_origen, embedding_destino, embedding_rango_horario,
                         embedding_salida, embedding_llegada, features_reshaped])
x = Flatten()(x)
ffn = Dense(ff_dim, activation='relu')(x)
ffn = Dropout(dropout_rate)(ffn)
ffn = Dense(1)(ffn)

model = Model(inputs=[input_origen, input_destino, input_rango_horario,
                      input_salida, input_llegada, features], outputs=ffn)
model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mse')

model.fit([X_train['Origen_int'], X_train['Destino_int'], X_train['Rango_Horario_Consulta_int'],
           X_train['Hora_Salida_Rango_int'], X_train['Hora_Llegada_Rango_int'],
           X_train[['Duracion_minutos', 'Directo_binario', 'Dias_hasta_vuelo']].values],
          y_train, epochs=100, batch_size=32, verbose=0)

y_pred = model.predict([X_val['Origen_int'], X_val['Destino_int'], X_val['Rango_Horario_Consulta_int'],
                        X_val['Hora_Salida_Rango_int'], X_val['Hora_Llegada_Rango_int'],
                        X_val[['Duracion_minutos', 'Directo_binario', 'Dias_hasta_vuelo']].values])

# Métricas finales
final_metrics_transformer_obj1E = pd.Series({
    'MAE': mean_absolute_error(y_val, y_pred),
    'MSE': mean_squared_error(y_val, y_pred),
    'RMSE': np.sqrt(mean_squared_error(y_val, y_pred)),
    'R2': r2_score(y_val, y_pred),
    'Training_Time': time.time() - start_time,
    'Best_Params': str(study.best_params)
})

print("Promedios finales de las métricas Transformer:")
print(final_metrics_transformer_obj1E)

"""## **XGBOOST**"""

import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error
import optuna
import numpy as np
import matplotlib.pyplot as plt
import time
import pandas as pd

# Leer dataset con embeddings entrenados para Tarifa
df_tarifa = pd.read_csv("embed_tarifa.csv")

# Separar características (X) y objetivo (y)
X = df_tarifa.drop(columns=['Tarifa'])
y = df_tarifa['Tarifa']

# División fija para todo el proceso
X_train_full, X_val_full, y_train_full, y_val_full = train_test_split(X, y, test_size=0.2, random_state=42)

# Optuna para encontrar los mejores hiperparámetros
def objective(trial):
    params = {
        'n_estimators': trial.suggest_int('n_estimators', 50, 100),
        'max_depth': trial.suggest_int('max_depth', 3, 10),
        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),
        'subsample': trial.suggest_float('subsample', 0.5, 1.0),
        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),
        'gamma': trial.suggest_float('gamma', 0, 5),
        'reg_alpha': trial.suggest_float('reg_alpha', 0, 1.0),
        'reg_lambda': trial.suggest_float('reg_lambda', 0, 1.0)
    }

    model = xgb.XGBRegressor(**params, random_state=42, verbosity=0)
    model.fit(X_train_full, y_train_full)

    y_pred = model.predict(X_val_full)
    rmse = np.sqrt(mean_squared_error(y_val_full, y_pred))
    return rmse

# Tiempo de ejecución para la optimización
opt_start_time = time.time()
study = optuna.create_study(direction="minimize")
study.optimize(objective, n_trials=10)
opt_time = time.time() - opt_start_time

print("Best parameters:", study.best_params)
print(f"Tiempo de optimización: {opt_time:.2f} segundos")

# Entrenamiento final con mejores parámetros
best_params = study.best_params
model_xgboost = xgb.XGBRegressor(**best_params, random_state=42, verbosity=0)

start_training_time = time.time()
model_xgboost.fit(X_train_full, y_train_full)
y_pred = model_xgboost.predict(X_val_full)
training_time = time.time() - start_training_time

# Métricas
mae = mean_absolute_error(y_val_full, y_pred)
mse = mean_squared_error(y_val_full, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_val_full, y_pred)

# Resultados finales
final_metrics_xgb_obj1E = pd.Series({
    'MAE': mae,
    'MSE': mse,
    'RMSE': rmse,
    'R2': r2,
    'Training_Time': training_time,
    'Best_Params': str(best_params)
})

print("\n Resultados finales del modelo XGBoost (sin TimeSeriesSplit):")
print(final_metrics_xgb_obj1E)

"""## **MODELO 6: KNN**"""

from sklearn.neighbors import KNeighborsRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error
import optuna
import numpy as np
import pandas as pd
import time

# Leer el archivo con embeddings entrenados para obj1
df_tarifa = pd.read_csv("embed_tarifa.csv")

# Separar características (X) y variable objetivo (y)
X = df_tarifa.drop(columns=['Tarifa'])
y = df_tarifa['Tarifa']

# División en entrenamiento y validación (80%-20%)
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)

# Optuna para encontrar los mejores hiperparámetros
def objective(trial):
    params = {
        'n_neighbors': trial.suggest_int('n_neighbors', 3, 15),
        'weights': trial.suggest_categorical('weights', ['uniform', 'distance']),
        'p': trial.suggest_int('p', 1, 2)
    }

    model = KNeighborsRegressor(**params)
    model.fit(X_train, y_train)

    y_pred = model.predict(X_val)
    rmse = np.sqrt(mean_squared_error(y_val, y_pred))

    return rmse

# Tiempo de optimización
opt_start_time = time.time()
study = optuna.create_study(direction="minimize")
study.optimize(objective, n_trials=10)
opt_time = time.time() - opt_start_time

print("Best parameters:", study.best_params)
print(f"Tiempo de optimización: {opt_time:.2f} segundos")

# Evaluación con los mejores parámetros
best_params = study.best_params
model_knn = KNeighborsRegressor(**best_params)

start_training_time = time.time()
model_knn.fit(X_train, y_train)
y_pred = model_knn.predict(X_val)
training_time = time.time() - start_training_time

# Métricas finales
mae = mean_absolute_error(y_val, y_pred)
mse = mean_squared_error(y_val, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_val, y_pred)

final_metrics_knn_obj1E = {
    'MAE': mae,
    'MSE': mse,
    'RMSE': rmse,
    'R2': r2,
    'Training_Time': training_time,
    'Best_Params': str(best_params)
}

print("\n Métricas finales (KNN obj1E con embeddings):")
print(final_metrics_knn_obj1E)

"""## **MODELO 7: ARBOL DE DESICION**"""

import pandas as pd
import numpy as np
from sklearn.tree import DecisionTreeRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error
import optuna
import time

# Leer el dataset con embeddings para el objetivo 1
df = pd.read_csv("embed_tarifa.csv")

# Definir variables predictoras (todas las columnas excepto la salida)
X = df.drop(columns=["Tarifa"])
y = df["Tarifa"]

# División en entrenamiento y validación (80%-20%)
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)

# Función objetivo para Optuna
def objective(trial):
    params = {
        "max_depth": trial.suggest_int("max_depth", 3, 20),
        "min_samples_split": trial.suggest_int("min_samples_split", 2, 10),
        "min_samples_leaf": trial.suggest_int("min_samples_leaf", 1, 10),
        "max_features": trial.suggest_categorical("max_features", ["sqrt", "log2", None])
    }

    model = DecisionTreeRegressor(**params)
    model.fit(X_train, y_train)
    y_pred = model.predict(X_val)

    rmse = np.sqrt(mean_squared_error(y_val, y_pred))
    return rmse

# Ejecutar Optuna para optimización
opt_start_time = time.time()
study = optuna.create_study(direction="minimize")
study.optimize(objective, n_trials=10)
opt_time = time.time() - opt_start_time

print("Best parameters:", study.best_params)
print(f"Tiempo de optimización: {opt_time:.2f} segundos")

# Entrenar modelo con mejores hiperparámetros
best_params = study.best_params
model_tree = DecisionTreeRegressor(**best_params)

start_training_time = time.time()
model_tree.fit(X_train, y_train)
y_pred = model_tree.predict(X_val)
training_time = time.time() - start_training_time

# Calcular métricas
mae = mean_absolute_error(y_val, y_pred)
mse = mean_squared_error(y_val, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_val, y_pred)

# Guardar métricas finales
final_metrics_tree_obj1E = {
    "MAE": mae,
    "MSE": mse,
    "RMSE": rmse,
    "R2": r2,
    "Training_Time": training_time,
    "Best_Params": str(best_params)
}

# Mostrar resultados
print("\n📊 Métricas finales (Árbol de Decisión obj1E con embeddings):")
print(final_metrics_tree_obj1E)

"""## **RANDOM FOREST**"""

import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error
import optuna
import time

# Cargar los embeddings entrenados para la variable Tarifa
df_tarifa = pd.read_csv("embed_tarifa.csv")

# Separar variables predictoras y objetivo
X = df_tarifa.drop(columns=["Tarifa"])
y = df_tarifa["Tarifa"]

# División simple de datos
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)

# Función objetivo para Optuna
def objective(trial):
    params = {
        'n_estimators': trial.suggest_int('n_estimators', 50, 100),
        'max_depth': trial.suggest_int('max_depth', 5, 20),
        'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),
        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),
        'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2', None])
    }

    model = RandomForestRegressor(**params, random_state=42)
    model.fit(X_train, y_train)
    y_pred = model.predict(X_val)

    rmse = np.sqrt(mean_squared_error(y_val, y_pred))
    return rmse

# Optimización con Optuna
opt_start_time = time.time()
study = optuna.create_study(direction="minimize")
study.optimize(objective, n_trials=10)
opt_time = time.time() - opt_start_time

print("Best parameters:", study.best_params)
print(f"Tiempo de optimización: {opt_time:.2f} segundos")

# Entrenamiento final con mejores hiperparámetros
best_params = study.best_params
model_rf = RandomForestRegressor(**best_params, random_state=42)

start_training_time = time.time()
model_rf.fit(X_train, y_train)
y_pred = model_rf.predict(X_val)
training_time = time.time() - start_training_time

# Cálculo de métricas
mae = mean_absolute_error(y_val, y_pred)
mse = mean_squared_error(y_val, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_val, y_pred)

# Guardar métricas finales
final_metrics_rf_obj1E = {
    "MAE": mae,
    "MSE": mse,
    "RMSE": rmse,
    "R2": r2,
    "Training_Time": training_time,
    "Best_Params": str(best_params)
}

# Mostrar resultados
print("\n📊 Métricas finales (Random Forest obj1E con embeddings):")
print(final_metrics_rf_obj1E)

"""## **RESULTADOS OBJETIVO 1**"""

import pandas as pd

# --- Lista de nombres de los modelos
model_names = [
    "LSTM",
    "GRU",
    "TCN",
    "Transformer",
    "XGBoost",
    "KNN",
    "Decision Tree",
    "Random Forest"
]

# --- Resultados de cada modelo (deben ser diccionarios)
obj1_results_E = [
    final_metrics_lstm_obj1E,
    final_gru_metrics_obj1E,
    final_metrics_tcn_obj1E,
    final_metrics_transformer_obj1E,
    final_metrics_xgb_obj1E,
    final_metrics_knn_obj1E,
    final_metrics_tree_obj1E,
    final_metrics_rf_obj1E
]

# --- Combinar nombres y resultados
resultados_con_nombres = []
for name, metrics in zip(model_names, obj1_results_E):
    resultados_con_nombres.append({'Modelo': name, **metrics})

# --- Crear DataFrame
df_resultados = pd.DataFrame(resultados_con_nombres)

# --- Guardar en CSV
df_resultados.to_csv("resultados_objetivo1_E.csv", index=False)

# --- Mostrar tabla
print("\n Tabla de resultados combinados:")
print(df_resultados)

"""# **EJECUCION MULTIOUTPUT**

## **LSTM**
"""

# Importar las librerías necesarias
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Cargar el dataset
df = pd.read_csv('flights_data_final.csv')

# Mostrar las primeras filas
print("Primeras 5 filas del dataset:")
display(df.head())

# --- LSTM Multioutput con Optuna y embeddings como hiperparámetro ---
import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Concatenate, Flatten, Lambda, Dropout
from tensorflow.keras.optimizers import Adam
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, accuracy_score, precision_score, recall_score, f1_score
import time
import optuna

# ----------------------------
# Dataset y preprocesamiento
# ----------------------------

# Variables independientes (sin incluir y_range)
X = df[['Origen_int', 'Destino_int', 'Duracion_minutos', 'Directo_binario',
        'Hora_Salida_Rango_int', 'Hora_Llegada_Rango_int']]

# Variables objetivo
y_price = df['Tarifa']
y_days = df['Dias_hasta_vuelo']
y_range = df['Rango_Horario_Consulta_int']

# Split
X_train, X_val, y_price_train, y_price_val, y_days_train, y_days_val, y_range_train, y_range_val = train_test_split(
    X, y_price, y_days, y_range, test_size=0.2, random_state=42)

# Copia para modificar
X_train = X_train.copy()
X_val = X_val.copy()

# Normalización de la variable continua
scaler = StandardScaler()
X_train[['Duracion_minutos']] = scaler.fit_transform(X_train[['Duracion_minutos']])
X_val[['Duracion_minutos']] = scaler.transform(X_val[['Duracion_minutos']])

# ----------------------------
# Modelo multitarea LSTM
# ----------------------------

def create_model(embedding_dim, learning_rate, lstm_units, dropout_rate):
    input_origen = Input(shape=(1,), name='input_origen')
    input_destino = Input(shape=(1,), name='input_destino')
    input_salida = Input(shape=(1,), name='input_salida')
    input_llegada = Input(shape=(1,), name='input_llegada')
    input_features = Input(shape=(2,), name='input_features')  # Duración + Directo

    # Embeddings
    embedding_origen = Embedding(input_dim=X['Origen_int'].nunique() + 1, output_dim=embedding_dim)(input_origen)
    embedding_destino = Embedding(input_dim=X['Destino_int'].nunique() + 1, output_dim=embedding_dim)(input_destino)
    embedding_salida = Embedding(input_dim=X['Hora_Salida_Rango_int'].nunique() + 1, output_dim=embedding_dim)(input_salida)
    embedding_llegada = Embedding(input_dim=X['Hora_Llegada_Rango_int'].nunique() + 1, output_dim=embedding_dim)(input_llegada)

    # Concatenación
    x = Concatenate()([
        Flatten()(embedding_origen),
        Flatten()(embedding_destino),
        Flatten()(embedding_salida),
        Flatten()(embedding_llegada),
        input_features
    ])

    x = Lambda(lambda x: tf.expand_dims(x, axis=1))(x)
    x = LSTM(lstm_units, return_sequences=False)(x)
    x = Dropout(dropout_rate)(x)

    # Salidas
    price_output = Dense(64, activation='relu')(x)
    price_output = Dense(1, name='price_output')(price_output)

    days_output = Dense(64, activation='relu')(x)
    days_output = Dense(1, name='days_output')(days_output)

    range_output = Dense(64, activation='relu')(x)
    range_output = Dense(y_range.nunique(), activation='softmax', name='range_output')(range_output)

    model = Model(inputs=[input_origen, input_destino, input_salida, input_llegada, input_features],
                  outputs=[price_output, days_output, range_output])

    model.compile(optimizer=Adam(learning_rate=learning_rate),
                  loss={'price_output': 'mse', 'days_output': 'mse', 'range_output': 'sparse_categorical_crossentropy'},
                  metrics={'price_output': 'mae', 'days_output': 'mae', 'range_output': 'accuracy'})
    return model

# ----------------------------
# Optuna tuning
# ----------------------------

def objective(trial):
    embedding_dim = trial.suggest_int('embedding_dim', 4, 16)
    lr = trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True)
    units = trial.suggest_int('lstm_units', 32, 128)
    drop = trial.suggest_float('dropout_rate', 0.2, 0.5)

    model = create_model(embedding_dim, lr, units, drop)

    model.fit([
        X_train['Origen_int'], X_train['Destino_int'],
        X_train['Hora_Salida_Rango_int'], X_train['Hora_Llegada_Rango_int'],
        X_train[['Duracion_minutos', 'Directo_binario']].values
    ],
    [y_price_train, y_days_train, y_range_train],
    epochs=100, batch_size=32, verbose=0)

    y_pred_price, y_pred_days, _ = model.predict([
        X_val['Origen_int'], X_val['Destino_int'],
        X_val['Hora_Salida_Rango_int'], X_val['Hora_Llegada_Rango_int'],
        X_val[['Duracion_minutos', 'Directo_binario']].values
    ])

    return mean_absolute_error(y_price_val, y_pred_price) + mean_absolute_error(y_days_val, y_pred_days)

# Ejecutar Optuna
study = optuna.create_study(direction='minimize')
study.optimize(objective, n_trials=10)  # puedes ajustar n_trials

# ----------------------------
# Entrenamiento final
# ----------------------------

best = study.best_params
model = create_model(best['embedding_dim'], best['learning_rate'], best['lstm_units'], best['dropout_rate'])

start_train = time.time()
model.fit([
    X_train['Origen_int'], X_train['Destino_int'],
    X_train['Hora_Salida_Rango_int'], X_train['Hora_Llegada_Rango_int'],
    X_train[['Duracion_minutos', 'Directo_binario']].values
], [y_price_train, y_days_train, y_range_train], epochs=100, batch_size=32, verbose=0)
end_train = time.time()

# ----------------------------
# Evaluación
# ----------------------------

y_price_pred, y_days_pred, y_range_pred = model.predict([
    X_val['Origen_int'], X_val['Destino_int'],
    X_val['Hora_Salida_Rango_int'], X_val['Hora_Llegada_Rango_int'],
    X_val[['Duracion_minutos', 'Directo_binario']].values
])

results_multi_lstm_E = pd.DataFrame([{
    'Modelo': 'LSTM (Embeddings)',
    'MAE_Tarifa': mean_absolute_error(y_price_val, y_price_pred),
    'MSE_Tarifa': mean_squared_error(y_price_val, y_price_pred),
    'RMSE_Tarifa': np.sqrt(mean_squared_error(y_price_val, y_price_pred)),
    'R2_Tarifa': r2_score(y_price_val, y_price_pred),

    'MAE_DiasAnt': mean_absolute_error(y_days_val, y_days_pred),
    'MSE_DiasAnt': mean_squared_error(y_days_val, y_days_pred),
    'RMSE_DiasAnt': np.sqrt(mean_squared_error(y_days_val, y_days_pred)),
    'R2_DiasAnt': r2_score(y_days_val, y_days_pred),

    'Accuracy_Rango': accuracy_score(y_range_val, np.argmax(y_range_pred, axis=1)),
    'Precision_Rango': precision_score(y_range_val, np.argmax(y_range_pred, axis=1), average='weighted'),
    'Recall_Rango': recall_score(y_range_val, np.argmax(y_range_pred, axis=1), average='weighted'),
    'F1_Rango': f1_score(y_range_val, np.argmax(y_range_pred, axis=1), average='weighted'),

    'Training_time': end_train - start_train,
}])
results_multi_lstm_E['Best_Params'] = [str(best)]
print(results_multi_lstm_E)

"""## **GRU**"""

import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Embedding, GRU, Dense, Concatenate, Flatten, Lambda, Dropout
from tensorflow.keras.optimizers import Adam
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, accuracy_score, precision_score, recall_score, f1_score
import optuna
import time

# Variables predictoras (sin incluir las variables objetivo)
X = df[['Origen_int', 'Destino_int', 'Duracion_minutos', 'Directo_binario', 'Hora_Salida_Rango_int', 'Hora_Llegada_Rango_int']]
y_price = df['Tarifa']
y_days = df['Dias_hasta_vuelo']
y_range = df['Rango_Horario_Consulta_int']

# División del dataset
X_train, X_val, y_price_train, y_price_val, y_days_train, y_days_val, y_range_train, y_range_val = train_test_split(
    X, y_price, y_days, y_range, test_size=0.2, random_state=42
)

# Normalización
scaler = StandardScaler()
X_train[['Duracion_minutos']] = scaler.fit_transform(X_train[['Duracion_minutos']])
X_val[['Duracion_minutos']] = scaler.transform(X_val[['Duracion_minutos']])

# Función para crear el modelo GRU
def create_gru_model(embedding_dim, learning_rate, gru_units, dropout_rate):
    input_origen = Input(shape=(1,), name='input_origen')
    input_destino = Input(shape=(1,), name='input_destino')
    input_salida = Input(shape=(1,), name='input_salida')
    input_llegada = Input(shape=(1,), name='input_llegada')
    input_features = Input(shape=(2,), name='input_features')  # Duracion_minutos, Directo_binario

    emb_origen = Embedding(input_dim=df['Origen_int'].nunique(), output_dim=embedding_dim)(input_origen)
    emb_destino = Embedding(input_dim=df['Destino_int'].nunique(), output_dim=embedding_dim)(input_destino)
    emb_salida = Embedding(input_dim=df['Hora_Salida_Rango_int'].nunique(), output_dim=embedding_dim)(input_salida)
    emb_llegada = Embedding(input_dim=df['Hora_Llegada_Rango_int'].nunique(), output_dim=embedding_dim)(input_llegada)

    x = Concatenate()([
        Flatten()(emb_origen), Flatten()(emb_destino),
        Flatten()(emb_salida), Flatten()(emb_llegada),
        input_features
    ])
    x = Lambda(lambda x: tf.expand_dims(x, axis=1))(x)
    x = GRU(gru_units, return_sequences=False)(x)
    x = Dropout(dropout_rate)(x)

    # Salidas
    price_output = Dense(64, activation='relu')(x)
    price_output = Dense(1, name='price_output')(price_output)

    days_output = Dense(64, activation='relu')(x)
    days_output = Dense(1, name='days_output')(days_output)

    range_output = Dense(64, activation='relu')(x)
    range_output = Dense(df['Rango_Horario_Consulta_int'].nunique(), activation='softmax', name='range_output')(range_output)

    model = Model(
        inputs=[input_origen, input_destino, input_salida, input_llegada, input_features],
        outputs=[price_output, days_output, range_output]
    )

    model.compile(
        optimizer=Adam(learning_rate=learning_rate),
        loss={
            'price_output': 'mse',
            'days_output': 'mse',
            'range_output': 'sparse_categorical_crossentropy'
        },
        metrics={
            'price_output': 'mae',
            'days_output': 'mae',
            'range_output': 'accuracy'
        }
    )

    return model

# Optuna
def objective(trial):
    embedding_dim = trial.suggest_int('embedding_dim', 4, 16)
    lr = trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True)
    units = trial.suggest_int('gru_units', 32, 128)
    drop = trial.suggest_float('dropout_rate', 0.2, 0.5)

    model = create_gru_model(embedding_dim, lr, units, drop)

    model.fit(
        [X_train['Origen_int'], X_train['Destino_int'],
         X_train['Hora_Salida_Rango_int'], X_train['Hora_Llegada_Rango_int'],
         X_train[['Duracion_minutos', 'Directo_binario']]],
        [y_price_train, y_days_train, y_range_train],
        validation_data=(
            [X_val['Origen_int'], X_val['Destino_int'],
             X_val['Hora_Salida_Rango_int'], X_val['Hora_Llegada_Rango_int'],
             X_val[['Duracion_minutos', 'Directo_binario']]],
            [y_price_val, y_days_val, y_range_val]),
        epochs=100,
        batch_size=32,
        verbose=0
    )

    preds = model.predict([
        X_val['Origen_int'], X_val['Destino_int'],
        X_val['Hora_Salida_Rango_int'], X_val['Hora_Llegada_Rango_int'],
        X_val[['Duracion_minutos', 'Directo_binario']]
    ], verbose=0)
    return mean_absolute_error(y_price_val, preds[0]) + mean_absolute_error(y_days_val, preds[1])

# Optimización
start_optuna = time.time()
study = optuna.create_study(direction='minimize')
study.optimize(objective, n_trials=10)
optuna_time = time.time() - start_optuna

# Entrenamiento final con mejores hiperparámetros
best_params = study.best_params
model = create_gru_model(best_params['embedding_dim'], best_params['learning_rate'],
                         best_params['gru_units'], best_params['dropout_rate'])

start_train = time.time()
model.fit(
    [X_train['Origen_int'], X_train['Destino_int'],
     X_train['Hora_Salida_Rango_int'], X_train['Hora_Llegada_Rango_int'],
     X_train[['Duracion_minutos', 'Directo_binario']]],
    [y_price_train, y_days_train, y_range_train],
    epochs=100,
    batch_size=32,
    verbose=1
)
train_time = time.time() - start_train

# Evaluación final
y_price_pred, y_days_pred, y_range_pred = model.predict([
    X_val['Origen_int'], X_val['Destino_int'],
    X_val['Hora_Salida_Rango_int'], X_val['Hora_Llegada_Rango_int'],
    X_val[['Duracion_minutos', 'Directo_binario']]
], verbose=0)
y_range_classes = np.argmax(y_range_pred, axis=1)

# Métricas
results_multi_gru_E = pd.DataFrame([{
    'Modelo': 'GRU',
    'MAE_Tarifa': mean_absolute_error(y_price_val, y_price_pred),
    'MSE_Tarifa': mean_squared_error(y_price_val, y_price_pred),
    'RMSE_Tarifa': np.sqrt(mean_squared_error(y_price_val, y_price_pred)),
    'R2_Tarifa': r2_score(y_price_val, y_price_pred),

    'MAE_DiasAnt': mean_absolute_error(y_days_val, y_days_pred),
    'MSE_DiasAnt': mean_squared_error(y_days_val, y_days_pred),
    'RMSE_DiasAnt': np.sqrt(mean_squared_error(y_days_val, y_days_pred)),
    'R2_DiasAnt': r2_score(y_days_val, y_days_pred),

    'Accuracy_Rango': accuracy_score(y_range_val, y_range_classes),
    'Precision_Rango': precision_score(y_range_val, y_range_classes, average='weighted', zero_division=0),
    'Recall_Rango': recall_score(y_range_val, y_range_classes, average='weighted', zero_division=0),
    'F1_Rango': f1_score(y_range_val, y_range_classes, average='weighted', zero_division=0),
    'Training_time': train_time,
    'Best_Params': str(best_params)
}])

print(results_multi_gru_E)

"""## **TCN**"""

import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Embedding, Dense, Concatenate, Flatten, Lambda
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error, accuracy_score, precision_score, recall_score, f1_score
from tcn import TCN
import optuna
import time

# Variables predictoras excluyendo la variable objetivo 'Rango_Horario_Consulta_int'
X = df[['Origen_int', 'Destino_int', 'Duracion_minutos', 'Directo_binario', 'Hora_Salida_Rango_int', 'Hora_Llegada_Rango_int']]
y_price = df['Tarifa']
y_days = df['Dias_hasta_vuelo']
y_range = df['Rango_Horario_Consulta_int']

X_train, X_val, y_price_train, y_price_val, y_days_train, y_days_val, y_range_train, y_range_val = train_test_split(
    X, y_price, y_days, y_range, test_size=0.2, random_state=42)

# Escalado de variables numéricas
scaler = StandardScaler()
X_train[['Duracion_minutos']] = scaler.fit_transform(X_train[['Duracion_minutos']])
X_val[['Duracion_minutos']] = scaler.transform(X_val[['Duracion_minutos']])

# Función para crear el modelo TCN multitarea
def create_tcn_model(trial):
    embedding_dim = trial.suggest_int('embedding_dim', 4, 16)
    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True)
    tcn_filters = trial.suggest_int('tcn_filters', 32, 128)
    kernel_size = trial.suggest_int('kernel_size', 2, 5)
    dropout_rate = trial.suggest_float('dropout_rate', 0.2, 0.5)

    input_origen = Input(shape=(1,), name='input_origen')
    input_destino = Input(shape=(1,), name='input_destino')
    input_salida = Input(shape=(1,), name='input_salida')
    input_llegada = Input(shape=(1,), name='input_llegada')
    input_features = Input(shape=(2,), name='input_features')  # Duración y Directo

    embedding_origen = Embedding(input_dim=X['Origen_int'].nunique(), output_dim=embedding_dim)(input_origen)
    embedding_destino = Embedding(input_dim=X['Destino_int'].nunique(), output_dim=embedding_dim)(input_destino)
    embedding_salida = Embedding(input_dim=X['Hora_Salida_Rango_int'].nunique(), output_dim=embedding_dim)(input_salida)
    embedding_llegada = Embedding(input_dim=X['Hora_Llegada_Rango_int'].nunique(), output_dim=embedding_dim)(input_llegada)

    x = Concatenate()([
        Flatten()(embedding_origen),
        Flatten()(embedding_destino),
        Flatten()(embedding_salida),
        Flatten()(embedding_llegada),
        input_features
    ])

    x = Lambda(lambda x: tf.expand_dims(x, axis=1))(x)

    x = TCN(nb_filters=tcn_filters, kernel_size=kernel_size, dropout_rate=dropout_rate, return_sequences=False)(x)

    price_output = Dense(64, activation='relu')(x)
    price_output = Dense(1, name='price_output')(price_output)

    days_output = Dense(64, activation='relu')(x)
    days_output = Dense(1, name='days_output')(days_output)

    range_output = Dense(64, activation='relu')(x)
    range_output = Dense(y_range.nunique(), activation='softmax', name='range_output')(range_output)

    model = Model(
        inputs=[input_origen, input_destino, input_salida, input_llegada, input_features],
        outputs=[price_output, days_output, range_output]
    )

    model.compile(
        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),
        loss={
            'price_output': 'mse',
            'days_output': 'mse',
            'range_output': 'sparse_categorical_crossentropy'
        },
        metrics={
            'price_output': 'mae',
            'days_output': 'mae',
            'range_output': 'accuracy'
        }
    )

    return model

# Función objetivo para Optuna
def objective(trial):
    model = create_tcn_model(trial)

    model.fit(
        [X_train['Origen_int'], X_train['Destino_int'], X_train['Hora_Salida_Rango_int'],
         X_train['Hora_Llegada_Rango_int'], X_train[['Duracion_minutos', 'Directo_binario']].values],
        [y_price_train, y_days_train, y_range_train],
        validation_data=([X_val['Origen_int'], X_val['Destino_int'], X_val['Hora_Salida_Rango_int'],
                          X_val['Hora_Llegada_Rango_int'], X_val[['Duracion_minutos', 'Directo_binario']].values],
                         [y_price_val, y_days_val, y_range_val]),
        epochs=100,
        batch_size=32,
        verbose=0
    )

    y_price_pred, y_days_pred, _ = model.predict(
        [X_val['Origen_int'], X_val['Destino_int'], X_val['Hora_Salida_Rango_int'],
         X_val['Hora_Llegada_Rango_int'], X_val[['Duracion_minutos', 'Directo_binario']].values],
        verbose=0
    )

    return mean_absolute_error(y_price_val, y_price_pred) + mean_absolute_error(y_days_val, y_days_pred)

# Optuna
optuna_start = time.time()
study = optuna.create_study(direction='minimize')
study.optimize(objective, n_trials=10)

# Entrenamiento final
best_params = study.best_params
final_trial = optuna.trial.FixedTrial(best_params)
model_tcn = create_tcn_model(final_trial)

training_start = time.time()
model_tcn.fit(
    [X_train['Origen_int'], X_train['Destino_int'], X_train['Hora_Salida_Rango_int'],
     X_train['Hora_Llegada_Rango_int'], X_train[['Duracion_minutos', 'Directo_binario']].values],
    [y_price_train, y_days_train, y_range_train],
    validation_data=([X_val['Origen_int'], X_val['Destino_int'], X_val['Hora_Salida_Rango_int'],
                      X_val['Hora_Llegada_Rango_int'], X_val[['Duracion_minutos', 'Directo_binario']].values],
                     [y_price_val, y_days_val, y_range_val]),
    epochs=100,
    batch_size=32,
    verbose=1
)
training_end = time.time()

# Evaluación
y_price_pred, y_days_pred, y_range_pred = model_tcn.predict(
    [X_val['Origen_int'], X_val['Destino_int'], X_val['Hora_Salida_Rango_int'],
     X_val['Hora_Llegada_Rango_int'], X_val[['Duracion_minutos', 'Directo_binario']].values],
    verbose=0
)

y_range_pred_classes = np.argmax(y_range_pred, axis=1)

results_multi_tcn_E = {
    'Modelo': 'TCN',
    'MAE_Tarifa': mean_absolute_error(y_price_val, y_price_pred),
    'R2_Tarifa': r2_score(y_price_val, y_price_pred),
    'RMSE_Tarifa': np.sqrt(mean_squared_error(y_price_val, y_price_pred)),
    'MSE_Tarifa': mean_squared_error(y_price_val, y_price_pred),

    'MAE_DiasAnt': mean_absolute_error(y_days_val, y_days_pred),
    'R2_DiasAnt': r2_score(y_days_val, y_days_pred),
    'RMSE_DiasAnt': np.sqrt(mean_squared_error(y_days_val, y_days_pred)),
    'MSE_DiasAnt': mean_squared_error(y_days_val, y_days_pred),

    'Accuracy_Rango': accuracy_score(y_range_val, y_range_pred_classes),
    'Precision_Rango': precision_score(y_range_val, y_range_pred_classes, average='weighted', zero_division=0),
    'Recall_Rango': recall_score(y_range_val, y_range_pred_classes, average='weighted', zero_division=0),
    'F1_Rango': f1_score(y_range_val, y_range_pred_classes, average='weighted', zero_division=0),

    'Training_time': training_end - training_start,
    'Best_Params': best_params
}

# Resultados
print("\nResultados TCN:")
for k, v in results_multi_tcn_E.items():
    print(f"{k}: {v:.4f}" if isinstance(v, float) else f"{k}: {v}")

"""## **TRANSFORMERS**"""

import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Embedding, Dense, Concatenate, Dropout, LayerNormalization
from tensorflow.keras.layers import MultiHeadAttention, Add, GlobalAveragePooling1D
from tensorflow.keras.optimizers import Adam
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, accuracy_score, precision_score, recall_score, f1_score
import optuna
import time

# Dataset
X = df[['Origen_int', 'Destino_int', 'Duracion_minutos', 'Directo_binario', 'Hora_Salida_Rango_int', 'Hora_Llegada_Rango_int']]
y_price = df['Tarifa']
y_days = df['Dias_hasta_vuelo']
y_range = df['Rango_Horario_Consulta_int']  # Variable objetivo, ya no se incluye en X

X_train, X_val, y_price_train, y_price_val, y_days_train, y_days_val, y_range_train, y_range_val = train_test_split(
    X, y_price, y_days, y_range, test_size=0.2, random_state=42)

# Normalización
scaler = StandardScaler()
X_train[['Duracion_minutos']] = scaler.fit_transform(X_train[['Duracion_minutos']])
X_val[['Duracion_minutos']] = scaler.transform(X_val[['Duracion_minutos']])

def transformer_block(x, heads, ff_dim, embedding_dim, dropout_rate):
    attention_output = MultiHeadAttention(num_heads=heads, key_dim=embedding_dim)(x, x)
    attention_output = Dropout(dropout_rate)(attention_output)
    out1 = LayerNormalization(epsilon=1e-6)(Add()([x, attention_output]))
    ffn_output = Dense(ff_dim, activation='relu')(out1)
    ffn_output = Dense(embedding_dim)(ffn_output)
    ffn_output = Dropout(dropout_rate)(ffn_output)
    return LayerNormalization(epsilon=1e-6)(Add()([out1, ffn_output]))

def create_model(embedding_dim, learning_rate, heads, ff_dim, dropout_rate):
    input_origen = Input(shape=(1,), name='input_origen')
    input_destino = Input(shape=(1,), name='input_destino')
    input_salida = Input(shape=(1,), name='input_salida')
    input_llegada = Input(shape=(1,), name='input_llegada')
    input_features = Input(shape=(2,), name='input_features')  # Duración y binario

    embedding_origen = Embedding(input_dim=X['Origen_int'].nunique(), output_dim=embedding_dim)(input_origen)
    embedding_destino = Embedding(input_dim=X['Destino_int'].nunique(), output_dim=embedding_dim)(input_destino)
    embedding_salida = Embedding(input_dim=X['Hora_Salida_Rango_int'].nunique(), output_dim=embedding_dim)(input_salida)
    embedding_llegada = Embedding(input_dim=X['Hora_Llegada_Rango_int'].nunique(), output_dim=embedding_dim)(input_llegada)

    embeddings = Concatenate(axis=1)([embedding_origen, embedding_destino, embedding_salida, embedding_llegada])
    transformer_output = transformer_block(embeddings, heads=heads, ff_dim=ff_dim, embedding_dim=embedding_dim, dropout_rate=dropout_rate)
    pooled_output = GlobalAveragePooling1D()(transformer_output)
    x = Concatenate()([pooled_output, input_features])

    # Outputs
    price_output = Dense(64, activation='relu')(x)
    price_output = Dense(1, name='price_output')(price_output)

    days_output = Dense(64, activation='relu')(x)
    days_output = Dense(1, name='days_output')(days_output)

    range_output = Dense(64, activation='relu')(x)
    range_output = Dense(y_range.nunique(), activation='softmax', name='range_output')(range_output)

    model = Model(inputs=[input_origen, input_destino, input_salida, input_llegada, input_features],
                  outputs=[price_output, days_output, range_output])

    model.compile(optimizer=Adam(learning_rate=learning_rate),
                  loss={'price_output': 'mse', 'days_output': 'mse', 'range_output': 'sparse_categorical_crossentropy'},
                  metrics={'price_output': 'mae', 'days_output': 'mae', 'range_output': 'accuracy'})
    return model

# Optuna
def objective(trial):
    embedding_dim = trial.suggest_int('embedding_dim', 4, 16)
    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True)
    heads = trial.suggest_int('heads', 1, 4)
    ff_dim = trial.suggest_int('ff_dim', 32, 128)
    dropout_rate = trial.suggest_float('dropout_rate', 0.2, 0.5)

    model = create_model(embedding_dim, learning_rate, heads, ff_dim, dropout_rate)

    model.fit([
        X_train['Origen_int'], X_train['Destino_int'],
        X_train['Hora_Salida_Rango_int'], X_train['Hora_Llegada_Rango_int'],
        X_train[['Duracion_minutos', 'Directo_binario']].values
    ], [y_price_train, y_days_train, y_range_train], epochs=100, batch_size=32, verbose=0)

    y_pred_price, y_pred_days, _ = model.predict([
        X_val['Origen_int'], X_val['Destino_int'],
        X_val['Hora_Salida_Rango_int'], X_val['Hora_Llegada_Rango_int'],
        X_val[['Duracion_minutos', 'Directo_binario']].values
    ])

    return mean_absolute_error(y_price_val, y_pred_price) + mean_absolute_error(y_days_val, y_pred_days)

study = optuna.create_study(direction='minimize')
study.optimize(objective, n_trials=10)

# Entrenamiento final con mejores parámetros
best = study.best_params
model = create_model(
    best['embedding_dim'],
    best['learning_rate'],
    best['heads'],
    best['ff_dim'],
    best['dropout_rate']
)
start_train = time.time()
model.fit([
    X_train['Origen_int'], X_train['Destino_int'],
    X_train['Hora_Salida_Rango_int'], X_train['Hora_Llegada_Rango_int'],
    X_train[['Duracion_minutos', 'Directo_binario']].values
], [y_price_train, y_days_train, y_range_train], epochs=100, batch_size=32, verbose=0)
end_train = time.time()
# Evaluación
y_price_pred, y_days_pred, y_range_pred = model.predict([
    X_val['Origen_int'], X_val['Destino_int'],
    X_val['Hora_Salida_Rango_int'], X_val['Hora_Llegada_Rango_int'],
    X_val[['Duracion_minutos', 'Directo_binario']].values
])

# Métricas
results_multi_transformer_E = pd.DataFrame([{
    'Modelo': 'Transformer',
    'MAE_Tarifa': mean_absolute_error(y_price_val, y_price_pred),
    'MSE_Tarifa': mean_squared_error(y_price_val, y_price_pred),
    'RMSE_Tarifa': np.sqrt(mean_squared_error(y_price_val, y_price_pred)),
    'R2_Tarifa': r2_score(y_price_val, y_price_pred),

    'MAE_DiasAnt': mean_absolute_error(y_days_val, y_days_pred),
    'MSE_DiasAnt': mean_squared_error(y_days_val, y_days_pred),
    'RMSE_DiasAnt': np.sqrt(mean_squared_error(y_days_val, y_days_pred)),
    'R2_DiasAnt': r2_score(y_days_val, y_days_pred),

    'Accuracy_Rango': accuracy_score(y_range_val, np.argmax(y_range_pred, axis=1)),
    'Precision_Rango': precision_score(y_range_val, np.argmax(y_range_pred, axis=1), average='weighted'),
    'Recall_Rango': recall_score(y_range_val, np.argmax(y_range_pred, axis=1), average='weighted'),
    'F1_Rango': f1_score(y_range_val, np.argmax(y_range_pred, axis=1), average='weighted'),

    'Training_time': end_train - start_train,
    'Best_Params': str(best)
}])

print(results_multi_transformer_E)

"""## **XGBOOST**"""

import pandas as pd
import numpy as np
import optuna
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import (
    mean_squared_error, mean_absolute_error, r2_score,
    accuracy_score, precision_score, recall_score, f1_score
)

# Cargar los embeddings si ya están almacenados en un CSV
df_embed = pd.read_csv("df_embeddings.csv")

# Definir columnas target
target_tarifa = 'Tarifa'
target_dias = 'Dias_hasta_vuelo'
target_rango = 'Rango_Horario_Consulta_int'

# Separar X e y
X = df_embed.drop([target_tarifa, target_dias, target_rango], axis=1)
y_price = df_embed[target_tarifa]
y_days = df_embed[target_dias]
y_range = df_embed[target_rango]

# Dividir en entrenamiento y validación
X_train, X_val, y_price_train, y_price_val, y_days_train, y_days_val, y_range_train, y_range_val = train_test_split(
    X, y_price, y_days, y_range, test_size=0.2, random_state=42
)

# Función de objetivo para regresión
def objective_regression(trial, y_train, y_val):
    params = {
        'objective': 'reg:squarederror',
        'eval_metric': 'rmse',
        'learning_rate': trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True),
        'max_depth': trial.suggest_int('max_depth', 2, 8),
        'n_estimators': trial.suggest_int('n_estimators', 20, 100),
    }
    model = xgb.XGBRegressor(**params)
    model.fit(X_train, y_train)
    preds = model.predict(X_val)
    return mean_squared_error(y_val, preds)

# Función de objetivo para clasificación
def objective_classification(trial):
    params = {
        'objective': 'multi:softprob',
        'eval_metric': 'mlogloss',
        'num_class': len(np.unique(y_range)),
        'learning_rate': trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True),
        'max_depth': trial.suggest_int('max_depth', 2, 8),
        'n_estimators': trial.suggest_int('n_estimators', 20, 100),
    }
    model = xgb.XGBClassifier(**params)
    model.fit(X_train, y_range_train)
    preds = model.predict(X_val)
    return 1.0 - accuracy_score(y_range_val, preds)

# Optuna: 3 iteraciones para cada tarea
study_price = optuna.create_study(direction='minimize')
study_price.optimize(lambda trial: objective_regression(trial, y_price_train, y_price_val), n_trials=10)

study_days = optuna.create_study(direction='minimize')
study_days.optimize(lambda trial: objective_regression(trial, y_days_train, y_days_val), n_trials=10)

study_range = optuna.create_study(direction='minimize')
study_range.optimize(objective_classification, n_trials=10)

start_training_time = time.time()
# Entrenar modelos finales con los mejores parámetros
model_price = xgb.train(
    study_price.best_params,
    xgb.DMatrix(X_train, label=y_price_train),
    num_boost_round=50
)

model_days = xgb.train(
    study_days.best_params,
    xgb.DMatrix(X_train, label=y_days_train),
    num_boost_round=50
)

clf_range = xgb.XGBClassifier(**study_range.best_params)
clf_range.fit(X_train, y_range_train)
training_time = time.time() - start_training_time
# Predicciones
price_preds = model_price.predict(xgb.DMatrix(X_val))
days_preds = model_days.predict(xgb.DMatrix(X_val))
range_preds = clf_range.predict(X_val)

# Métricas de evaluación
results_multi_xgboost_E = pd.DataFrame([{
    'Modelo': 'XGBoost',

    'MAE_Tarifa': mean_absolute_error(y_price_val, price_preds),
    'MSE_Tarifa': mean_squared_error(y_price_val, price_preds),
    'RMSE_Tarifa': np.sqrt(mean_squared_error(y_price_val, price_preds)),
    'R2_Tarifa': r2_score(y_price_val, price_preds),

    'MAE_DiasAnt': mean_absolute_error(y_days_val, days_preds),
    'MSE_DiasAnt': mean_squared_error(y_days_val, days_preds),
    'RMSE_DiasAnt': np.sqrt(mean_squared_error(y_days_val, days_preds)),
    'R2_DiasAnt': r2_score(y_days_val, days_preds),

    'Accuracy_Rango': accuracy_score(y_range_val, range_preds),
    'Precision_Rango': precision_score(y_range_val, range_preds, average='weighted', zero_division=0),
    'Recall_Rango': recall_score(y_range_val, range_preds, average='weighted', zero_division=0),
    'F1_Rango': f1_score(y_range_val, range_preds, average='weighted', zero_division=0),

    'Training_time': training_time,
    'Best_Params': str({
        'Tarifa': study_price.best_params,
        'DiasAnt': study_days.best_params,
        'Rango': study_range.best_params
    })
}])

print(results_multi_xgboost_E)

"""## **KNN**"""

import time
import pandas as pd
import numpy as np
from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, accuracy_score, precision_score, recall_score, f1_score
import optuna

# Asegúrate de haber cargado el dataset de embeddings generado previamente
df_embed = pd.read_csv("df_embeddings.csv")  # o reemplaza por tu DataFrame existente

# Variables de entrada (solo embeddings)
embed_cols = [col for col in df_embed.columns if col.startswith("embed_feat")]
X = df_embed[embed_cols]

# Variables objetivo
y_price = df_embed['Tarifa']
y_days = df_embed['Dias_hasta_vuelo']
y_range = df_embed['Rango_Horario_Consulta_int']

# División del dataset
X_train, X_val, y_price_train, y_price_val, y_days_train, y_days_val, y_range_train, y_range_val = train_test_split(
    X, y_price, y_days, y_range, test_size=0.2, random_state=42
)

# ------------------------
# OPTUNA
# ------------------------

def objective_knn_reg(trial, y_train, y_val):
    params = {
        'n_neighbors': trial.suggest_int('n_neighbors', 3, 15),
        'weights': trial.suggest_categorical('weights', ['uniform', 'distance']),
        'p': trial.suggest_int('p', 1, 2)
    }
    model = KNeighborsRegressor(**params)
    model.fit(X_train, y_train)
    y_pred = model.predict(X_val)
    return mean_absolute_error(y_val, y_pred)

def objective_knn_cls(trial):
    params = {
        'n_neighbors': trial.suggest_int('n_neighbors', 3, 15),
        'weights': trial.suggest_categorical('weights', ['uniform', 'distance']),
        'p': trial.suggest_int('p', 1, 2)
    }
    model = KNeighborsClassifier(**params)
    model.fit(X_train, y_range_train)
    y_pred = model.predict(X_val)
    return 1 - accuracy_score(y_range_val, y_pred)

study_price = optuna.create_study(direction='minimize')
study_price.optimize(lambda trial: objective_knn_reg(trial, y_price_train, y_price_val), n_trials=10)

study_days = optuna.create_study(direction='minimize')
study_days.optimize(lambda trial: objective_knn_reg(trial, y_days_train, y_days_val), n_trials=10)

study_range = optuna.create_study(direction='minimize')
study_range.optimize(objective_knn_cls, n_trials=10)


# ------------------------
# ENTRENAMIENTO FINAL
# ------------------------

start_optuna = time.time()
model_price = KNeighborsRegressor(**study_price.best_params)
model_price.fit(X_train, y_price_train)
y_price_pred = model_price.predict(X_val)

model_days = KNeighborsRegressor(**study_days.best_params)
model_days.fit(X_train, y_days_train)
y_days_pred = model_days.predict(X_val)

model_range = KNeighborsClassifier(**study_range.best_params)
model_range.fit(X_train, y_range_train)
y_range_pred_classes = model_range.predict(X_val)
end_optuna = time.time()
# ------------------------
# EVALUACIÓN Y RESULTADOS
# ------------------------

results_multi_knn_E = pd.DataFrame([{
    'Modelo': 'KNN',

    'MAE_Tarifa': mean_absolute_error(y_price_val, y_price_pred),
    'MSE_Tarifa': mean_squared_error(y_price_val, y_price_pred),
    'RMSE_Tarifa': np.sqrt(mean_squared_error(y_price_val, y_price_pred)),
    'R2_Tarifa': r2_score(y_price_val, y_price_pred),

    'MAE_DiasAnt': mean_absolute_error(y_days_val, y_days_pred),
    'MSE_DiasAnt': mean_squared_error(y_days_val, y_days_pred),
    'RMSE_DiasAnt': np.sqrt(mean_squared_error(y_days_val, y_days_pred)),
    'R2_DiasAnt': r2_score(y_days_val, y_days_pred),

    'Accuracy_Rango': accuracy_score(y_range_val, y_range_pred_classes),
    'Precision_Rango': precision_score(y_range_val, y_range_pred_classes, average='weighted'),
    'Recall_Rango': recall_score(y_range_val, y_range_pred_classes, average='weighted'),
    'F1_Rango': f1_score(y_range_val, y_range_pred_classes, average='weighted'),

    'Training_time': time.time() - end_optuna,
}])

# Mostrar mejores hiperparámetros por cada tarea
results_multi_knn_E['Best_Params'] = [str({
    'Tarifa': study_price.best_params,
    'Dias': study_days.best_params,
    'Rango': study_range.best_params
})]

print(results_multi_knn_E)

"""## **ARBOL DE DESICION**"""

import time
import pandas as pd
import numpy as np
from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import (
    mean_absolute_error, mean_squared_error, r2_score,
    accuracy_score, precision_score, recall_score, f1_score
)
import optuna

# Asegúrate de tener cargado tu DataFrame con embeddings y targets:
df_embed = pd.read_csv("df_embeddings.csv")

X = df_embed[[col for col in df_embed.columns if col.startswith("embed_feat_")]]
y_price = df_embed["Tarifa"]
y_days = df_embed["Dias_hasta_vuelo"]
y_range = df_embed["Rango_Horario_Consulta_int"]

X_train, X_val, y_price_train, y_price_val, y_days_train, y_days_val, y_range_train, y_range_val = train_test_split(
    X, y_price, y_days, y_range, test_size=0.2, random_state=42
)

# ---------------------- OPTIMIZACIÓN CON OPTUNA ---------------------- #
start_optuna = time.time()

# Función para regresión
def objective_dt_reg(trial, y_train, y_val):
    params = {
        "max_depth": trial.suggest_int("max_depth", 50, 100),
        "min_samples_split": trial.suggest_int("min_samples_split", 2, 10)
    }
    model = DecisionTreeRegressor(**params)
    model.fit(X_train, y_train)
    preds = model.predict(X_val)
    return mean_absolute_error(y_val, preds)

# Función para clasificación
def objective_dt_cls(trial):
    params = {
        "max_depth": trial.suggest_int("max_depth", 50, 100),
        "min_samples_split": trial.suggest_int("min_samples_split", 2, 10)
    }
    model = DecisionTreeClassifier(**params)
    model.fit(X_train, y_range_train)
    preds = model.predict(X_val)
    return 1 - accuracy_score(y_range_val, preds)

# Optuna por tarea
study_dt_price = optuna.create_study(direction="minimize")
study_dt_price.optimize(lambda trial: objective_dt_reg(trial, y_price_train, y_price_val), n_trials=10)

study_dt_days = optuna.create_study(direction="minimize")
study_dt_days.optimize(lambda trial: objective_dt_reg(trial, y_days_train, y_days_val), n_trials=10)

study_dt_range = optuna.create_study(direction="minimize")
study_dt_range.optimize(objective_dt_cls, n_trials=10)

end_optuna = time.time()

# ---------------------- ENTRENAMIENTO FINAL ---------------------- #
model_dt_price = DecisionTreeRegressor(**study_dt_price.best_params)
model_dt_price.fit(X_train, y_price_train)
y_pred_dt_price = model_dt_price.predict(X_val)

model_dt_days = DecisionTreeRegressor(**study_dt_days.best_params)
model_dt_days.fit(X_train, y_days_train)
y_pred_dt_days = model_dt_days.predict(X_val)

model_dt_range = DecisionTreeClassifier(**study_dt_range.best_params)
model_dt_range.fit(X_train, y_range_train)
y_pred_dt_range = model_dt_range.predict(X_val)

# ---------------------- MÉTRICAS ---------------------- #
results_multi_dt_E = pd.DataFrame([{
    "Modelo": "Decision Tree Multioutput (Embeddings)",

    "MAE_Tarifa": mean_absolute_error(y_price_val, y_pred_dt_price),
    "MSE_Tarifa": mean_squared_error(y_price_val, y_pred_dt_price),
    "RMSE_Tarifa": np.sqrt(mean_squared_error(y_price_val, y_pred_dt_price)),
    "R2_Tarifa": r2_score(y_price_val, y_pred_dt_price),

    "MAE_DiasAnt": mean_absolute_error(y_days_val, y_pred_dt_days),
    "MSE_DiasAnt": mean_squared_error(y_days_val, y_pred_dt_days),
    "RMSE_DiasAnt": np.sqrt(mean_squared_error(y_days_val, y_pred_dt_days)),
    "R2_DiasAnt": r2_score(y_days_val, y_pred_dt_days),

    "Accuracy_Rango": accuracy_score(y_range_val, y_pred_dt_range),
    "Precision_Rango": precision_score(y_range_val, y_pred_dt_range, average="weighted"),
    "Recall_Rango": recall_score(y_range_val, y_pred_dt_range, average="weighted"),
    "F1_Rango": f1_score(y_range_val, y_pred_dt_range, average="weighted"),

    "Training_time": time.time() - end_optuna,

}])

results_multi_dt_E["Best_Params"] = [str({
    "Tarifa": study_dt_price.best_params,
    "Dias_hasta_vuelo": study_dt_days.best_params,
    "Rango_Horario_Consulta_int": study_dt_range.best_params
})]

print(results_multi_dt_E)

"""## **RANDOM FOREST**"""

import time
import optuna
import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, accuracy_score, precision_score, recall_score, f1_score
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# -------------------- CARGA DEL DATASET CON EMBEDDINGS --------------------
df_embed = pd.read_csv('df_embeddings.csv')  # Ajusta la ruta

# Separación de variables
X = df_embed.drop(columns=['Tarifa', 'Dias_hasta_vuelo', 'Rango_Horario_Consulta_int'])
y_price = df_embed['Tarifa']
y_days = df_embed['Dias_hasta_vuelo']
y_range = df_embed['Rango_Horario_Consulta_int']

# División
X_train, X_val, y_price_train, y_price_val, y_days_train, y_days_val, y_range_train, y_range_val = train_test_split(
    X, y_price, y_days, y_range, test_size=0.2, random_state=42
)

# -------------------- OPTUNA --------------------
start_optuna = time.time()

def objective_rf_reg(trial, y_train, y_val):
    params = {
        'n_estimators': trial.suggest_int('n_estimators', 50, 300, step=50),
        'max_depth': trial.suggest_int('max_depth', 3, 20),
        'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),
        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 5)
    }
    model = RandomForestRegressor(**params, random_state=42)
    model.fit(X_train, y_train)
    preds = model.predict(X_val)
    return mean_absolute_error(y_val, preds)

def objective_rf_cls(trial):
    params = {
        'n_estimators': trial.suggest_int('n_estimators', 50, 300, step=50),
        'max_depth': trial.suggest_int('max_depth', 3, 20),
        'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),
        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 5)
    }
    model = RandomForestClassifier(**params, random_state=42)
    model.fit(X_train, y_range_train)
    preds = model.predict(X_val)
    return 1 - accuracy_score(y_range_val, preds)

# Estudios
study_rf_price = optuna.create_study(direction='minimize')
study_rf_price.optimize(lambda trial: objective_rf_reg(trial, y_price_train, y_price_val), n_trials=10)

study_rf_days = optuna.create_study(direction='minimize')
study_rf_days.optimize(lambda trial: objective_rf_reg(trial, y_days_train, y_days_val), n_trials=10)

study_rf_range = optuna.create_study(direction='minimize')
study_rf_range.optimize(objective_rf_cls, n_trials=10)

end_optuna = time.time()

# -------------------- ENTRENAMIENTO FINAL --------------------
model_rf_price = RandomForestRegressor(**study_rf_price.best_params, random_state=42)
model_rf_price.fit(X_train, y_price_train)
y_pred_rf_price = model_rf_price.predict(X_val)

model_rf_days = RandomForestRegressor(**study_rf_days.best_params, random_state=42)
model_rf_days.fit(X_train, y_days_train)
y_pred_rf_days = model_rf_days.predict(X_val)

model_rf_range = RandomForestClassifier(**study_rf_range.best_params, random_state=42)
model_rf_range.fit(X_train, y_range_train)
y_pred_rf_range = model_rf_range.predict(X_val)

# -------------------- MÉTRICAS --------------------
results_multi_rf_E = pd.DataFrame([{
    'Modelo': 'Random Forest',

    'MAE_Tarifa': mean_absolute_error(y_price_val, y_pred_rf_price),
    'MSE_Tarifa': mean_squared_error(y_price_val, y_pred_rf_price),
    'RMSE_Tarifa': np.sqrt(mean_squared_error(y_price_val, y_pred_rf_price)),
    'R2_Tarifa': r2_score(y_price_val, y_pred_rf_price),

    'MAE_DiasAnt': mean_absolute_error(y_days_val, y_pred_rf_days),
    'MSE_DiasAnt': mean_squared_error(y_days_val, y_pred_rf_days),
    'RMSE_DiasAnt': np.sqrt(mean_squared_error(y_days_val, y_pred_rf_days)),
    'R2_DiasAnt': r2_score(y_days_val, y_pred_rf_days),

    'Accuracy_Rango': accuracy_score(y_range_val, y_pred_rf_range),
    'Precision_Rango': precision_score(y_range_val, y_pred_rf_range, average='weighted'),
    'Recall_Rango': recall_score(y_range_val, y_pred_rf_range, average='weighted'),
    'F1_Rango': f1_score(y_range_val, y_pred_rf_range, average='weighted'),

    'Training_time': time.time() - end_optuna,
    'Best_Params': str({
        'Tarifa': study_rf_price.best_params,
        'DiasAnt': study_rf_days.best_params,
        'Rango': study_rf_range.best_params
    })
}])

print(results_multi_rf_E)

"""## **ALMACENAR RESULTADOS**"""

import pandas as pd

# --- Consolidar todos los resultados en una lista
results_multi_E = [
    results_multi_lstm_E ,
    results_multi_gru_E,
    pd.DataFrame([results_multi_tcn_E]), # Convert the dictionary to a DataFrame
    results_multi_transformer_E,
    results_multi_xgboost_E,
    results_multi_knn_E,
    results_multi_dt_E,
    results_multi_rf_E
]

# --- Crear DataFrame by concatenating the list of DataFrames
df_results_multi_E = pd.concat(results_multi_E, ignore_index=True)


# --- Guardar a CSV
df_results_multi_E.to_csv("resultados_modelos_multioutput.csv", index=False)

# --- Mostrar resultados como tabla
from IPython.display import display
display(df_results_multi_E)